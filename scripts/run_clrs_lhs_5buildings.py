# -*- coding: utf-8 -*-
"""
run_clrs_lhs_5buildings.py

åŠŸèƒ½ï¼š
- è‡ªåŠ¨é€‰æ‹© 5 æ ‹æ¥¼ï¼ˆcofactor åˆ™è·¨ç±»å‹é€‰ï¼Œå…¶ä»–æ•°æ®é›†é¡ºåºé€‰ 5 æ ‹ï¼‰
- ç”Ÿæˆ 16 ç»„ CLRS è¶…å‚çš„ LHS è®¡åˆ’ï¼ˆå›ºå®šéšæœºç§å­ï¼›sigma_hi ç”¨ log é‡‡æ · + è‹¥å¹² run ç½® 0ï¼‰
- é€ run Ã— æ¥¼ è°ƒç”¨ evaluator è„šæœ¬ï¼ˆsingle_building_cvrmse168.pyï¼‰è®¡ç®— CVRMSE@168ï¼ˆvalid-only å£å¾„ï¼‰
- æ±‡æ€»æ‰€æœ‰ç»“æœå¹¶ç»˜å›¾ï¼ˆçƒ­åŠ›å›¾ + æ¯æ ‹æ¥¼æŠ˜çº¿ï¼‰

ç”¨æ³•ç¤ºä¾‹ï¼š
python run_clrs_lhs_5buildings.py \
  --baseline_ckpt /path/to/BuildMoE-top-k-2-without-shared-export_best_val.pt \
  --evaluator_py ./single_building_cvrmse168.py \
  --output_dir ./lhs_screen_results
"""

import argparse
import json
import os
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt


# -------------------------
# å›ºå®šï¼šcofactor ç±»å‹æ˜ å°„ï¼ˆç”¨äºå¤šæ ·åŒ–é€‰æ¥¼ï¼‰
# -------------------------
COFACTOR_TYPE = {
    "Kindergarten": [
        "building6396",
        "building6398",
        "building6402",
        "building6405",
        "building6406",
        "building6407",
        "building6409",
        "building6415",
        "building6419",
        "building6421",
        "building6422",
        "building6425",
        "building6426",
        "building6428",
        "building6429",
        "building6433",
        "building6434",
        "building6437",
        "building6439",
        "building6443",
    ],
    "School": [
        "building6397",
        "building6400",
        "building6404",
        "building6408",
        "building6413",
        "building6414",
        "building6416",
        "building6418",
        "building6420",
        "building6424",
        "building6431",
        "building6432",
        "building6438",
        "building6440",
        "building6444",
        "building6445",
    ],
    "NursingHome": [
        "building6399",
        "building6410",
        "building6412",
        "building6417",
        "building6423",
        "building6436",
        "building6442",
    ],
    "Office": ["building6411", "building6441"],
}


# -------------------------
# é€‰å– 5 æ ‹æ¥¼
# -------------------------
def pick_five_buildings(output_dir: Path, seed: int = 2025) -> List[dict]:
    """
    é€‰ 5 æ ‹ï¼š
      - cofactor: Kindergarten/School/NursingHome/Office å„ 1 æ ‹ï¼ˆéšæœºï¼Œå›ºå®šç§å­ï¼‰
      - university: å­¦ç”Ÿå…¬å¯“ A/B éšæœº 1 æ ‹
    è¿”å›ï¼š[{"dataset":"cofactor","building":"..."}, ..., {"dataset":"university","building":"A|B"}]
    åŒæ—¶å†™å‡º selected_buildings.txt ä»¥ä¾¿å¤ç°
    """
    import random

    random.seed(seed)

    # å››ç±»å„éšæœº 1 æ ‹
    chosen = []
    for cat in ["Kindergarten", "School", "NursingHome", "Office"]:
        pool = COFACTOR_TYPE[cat]
        bid = random.choice(pool)
        chosen.append({"dataset": "cofactor", "building": bid})

    # å­¦ç”Ÿå…¬å¯“ï¼ˆå†…ç½®ï¼Œä¸ä¾èµ–å¤–éƒ¨å…¥å‚ï¼‰
    uni_bid = random.choice(["A", "B"])
    chosen.append({"dataset": "university", "building": uni_bid})

    # å†™å‡ºé€‰æ‹©ç»“æœ
    output_dir.mkdir(parents=True, exist_ok=True)
    with (output_dir / "selected_buildings.txt").open("w", encoding="utf-8") as f:
        for rec in chosen:
            f.write(f"{rec['dataset']},{rec['building']}\n")

    print("âœ… æœ¬æ¬¡ç”¨äº LHS å¾®è°ƒå®éªŒçš„ 5 æ ‹æ¥¼ï¼š")
    for rec in chosen:
        print(f"  {rec['dataset']:<12} â†’ {rec['building']}")
    print(f"å·²å†™å‡º â†’ {output_dir / 'selected_buildings.txt'}")

    return chosen


# -------------------------
# ç”Ÿæˆ 16 ç»„ LHSï¼ˆsigma_hi: log é‡‡æ · + é›¶å™ªå£°å¯¹ç…§ï¼‰
# -------------------------
def latin_hypercube_1d(n: int) -> np.ndarray:
    """
    æ ‡å‡† [0,1) LHSï¼šn ä¸ªç­‰å®½ bin å†…å„é‡‡ 1 æ¬¡ï¼Œç„¶åæ•´ä½“æ‰“ä¹±ã€‚
    """
    bins = np.linspace(0.0, 1.0, n + 1)
    u = bins[:-1] + (bins[1:] - bins[:-1]) * np.random.rand(n)
    np.random.shuffle(u)
    return u


def make_16runs_clrs_plan(
    seed: int = 2025, n_runs: int = 16, n_sigma_zero: int = 2
) -> pd.DataFrame:
    """
    7 ä¸ª CLRS æ—‹é’®ï¼š
      - rho_star:   0.75~0.95   (linear)
      - k_fb:       0.05~0.40   (linear)
      - c_pulse:    0.20~2.00   (linear)
      - tau_hi:     2.00~3.00   (linear)
      - sigma_hi:   0~0.06      (log é‡‡æ · + æ˜¾å¼ 0ï¼›å¯¹ç…§ç”¨ n_sigma_zero æ¡)
      - phi1:       0.10~0.25   (linear)
      - phi2:       0.55~0.75   (linear)
    å›ºå®šé¡¹ï¼š
      - tau_lo=1.0, sigma_lo=0.0, alpha_ema=0.1, tau_min=1.0, tau_max=3.0,
        sigma_min=0.0, sigma_max=0.1
    """
    np.random.seed(seed)
    df = pd.DataFrame({"run_id": np.arange(1, n_runs + 1)})

    # çº¿æ€§å£å¾„
    def lin_range(lo, hi):
        u = latin_hypercube_1d(n_runs)
        return lo + (hi - lo) * u

    df["rho_star"] = lin_range(0.75, 0.95)
    df["k_fb"] = lin_range(0.05, 0.40)
    df["c_pulse"] = lin_range(0.20, 2.00)
    df["tau_hi"] = lin_range(2.00, 3.00)
    df["phi1"] = lin_range(0.10, 0.25)
    df["phi2"] = lin_range(0.55, 0.75)

    # sigma_hi: log é‡‡æ ·ï¼ˆæ’é™¤ 0ï¼‰ï¼Œå†éšæœºæŒ‘è‹¥å¹² run ç½® 0
    lo, hi = 1e-4, 6e-2
    u = latin_hypercube_1d(n_runs)
    sigma_vals = lo * (hi / lo) ** u  # å¯¹åº” log-uniform
    # éšæœºç½®é›¶çš„ç´¢å¼•
    zero_idx = np.random.choice(
        np.arange(n_runs), size=min(n_sigma_zero, n_runs), replace=False
    )
    sigma_vals[zero_idx] = 0.0
    df["sigma_hi"] = sigma_vals

    # å›ºå®šé¡¹ï¼ˆä»…è®°å½•åœ¨ CSV ä¾¿äºå¤ç°ï¼‰
    df["tau_lo"] = 1.00
    df["sigma_lo"] = 0.00
    df["alpha_ema"] = 0.10
    df["tau_min"] = 1.00
    df["tau_max"] = 3.00
    df["sigma_min"] = 0.00
    df["sigma_max"] = 0.10
    df["comment"] = "16-run LHS; sigma_hi log + zeros; Î»_aux fixed (not in plan)."

    # åˆ—é¡ºåºå‹å¥½åŒ–
    cols = [
        "run_id",
        "rho_star",
        "k_fb",
        "c_pulse",
        "tau_hi",
        "sigma_hi",
        "phi1",
        "phi2",
        "tau_lo",
        "sigma_lo",
        "alpha_ema",
        "tau_min",
        "tau_max",
        "sigma_min",
        "sigma_max",
        "comment",
    ]
    return df[cols]


# -------------------------
# è¯„æµ‹æ‰§è¡Œ
# -------------------------
def run_one_eval(
    evaluator_py: Path,
    baseline_ckpt: Path,
    dataset_name: str,
    building_id: str,
    device: str,
    out_dir_for_building: Path,
    plan_csv: Path,
    lhs_run: int,
    context_len: int = 168,
    pred_len: int = 168,
    batch_size: int = 64,
    do_finetune: bool = True,
    ft_batch_size: int = 64,
    extra_env: Optional[Dict[str, str]] = None,
) -> Optional[Path]:
    """
    è°ƒç”¨ single_building_cvrmse168.pyï¼Œè¿”å›å…¶è¾“å‡º CSV è·¯å¾„ï¼ˆæˆ– None è¡¨å¤±è´¥ï¼‰ã€‚
    """
    out_dir_for_building.mkdir(parents=True, exist_ok=True)

    cmd = [
        sys.executable,
        str(evaluator_py),
        "--baseline_ckpt",
        str(baseline_ckpt),
        "--dataset_name",
        dataset_name,
        "--building_id",
        building_id,
        "--context_len",
        str(context_len),
        "--pred_len",
        str(pred_len),
        "--batch_size",
        str(batch_size),
        "--device",
        device,
        "--output_dir",
        str(out_dir_for_building),
        "--clrs_plan_csv",
        str(plan_csv),
        "--lhs_run",
        str(lhs_run),
    ]
    if do_finetune:
        cmd += ["--do_finetune", "--ft_batch_size", str(ft_batch_size)]

    env = os.environ.copy()
    if extra_env:
        env.update(extra_env)

    print("â–¶ï¸  Running:", " ".join(cmd))
    try:
        p = subprocess.run(cmd, env=env, capture_output=True, text=True, check=False)
        if p.returncode != 0:
            print("âŒ evaluator å¤±è´¥ï¼š", p.stderr.strip())
            return None
        # evaluator ä¼šå†™å‡º {dataset}_{building}_CVRMSE168.csv åˆ° out_dir_for_building
        # æˆ‘ä»¬å°è¯•è¯»å–é‚£ä¸ªæ–‡ä»¶
        out_csv = out_dir_for_building / f"{dataset_name}_{building_id}_CVRMSE168.csv"
        if not out_csv.exists():
            print(f"âš ï¸ æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶ï¼š{out_csv}")
            print("stdout:", p.stdout[-5000:])
            print("stderr:", p.stderr[-5000:])
            return None
        return out_csv
    except Exception as e:
        print(f"âŒ å­è¿›ç¨‹å¼‚å¸¸ï¼š{e}")
        return None


# -------------------------
# ç”»å›¾
# -------------------------
def plot_heatmap(df_sum: pd.DataFrame, out_path: Path) -> None:
    """
    df_sum: åŒ…å«åˆ— ['run_id', <building columns>]
    """
    bids = [c for c in df_sum.columns if c not in ["run_id", "run_mean", "run_std"]]
    mat = df_sum[bids].values
    plt.figure(figsize=(max(6, 0.6 * len(bids) + 2), 8))
    plt.imshow(mat, aspect="auto")
    plt.colorbar(label="CVRMSE_168 (%)")
    plt.yticks(np.arange(len(df_sum)), df_sum["run_id"].tolist())
    plt.xticks(np.arange(len(bids)), bids, rotation=45, ha="right")
    plt.title("CVRMSE@168 Heatmap (runs Ã— buildings)")
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()


def plot_per_building_lines(df_sum: pd.DataFrame, out_dir: Path) -> None:
    bids = [c for c in df_sum.columns if c not in ["run_id", "run_mean", "run_std"]]
    for b in bids:
        plt.figure(figsize=(7, 4))
        plt.plot(df_sum["run_id"], df_sum[b], marker="o")
        plt.xlabel("run_id")
        plt.ylabel("CVRMSE_168 (%)")
        plt.title(f"CVRMSE@168 vs run_id â€” {b}")
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(out_dir / f"line_{b}.png", dpi=150)
        plt.close()


# -------------------------
# ä¸»ç¨‹åº
# -------------------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--baseline_ckpt", type=Path, required=True)
    ap.add_argument("--evaluator_py", type=Path, required=True)
    ap.add_argument("--output_dir", type=Path, default=Path("./lhs_screen_results"))
    ap.add_argument("--dataset_name", type=str, default="cofactor")
    ap.add_argument("--context_len", type=int, default=168)
    ap.add_argument("--pred_len", type=int, default=168)
    ap.add_argument("--device", type=str, default="cuda")
    ap.add_argument("--random_seed", type=int, default=2025)
    ap.add_argument("--do_finetune", action="store_true")
    ap.add_argument("--ft_batch_size", type=int, default=64)
    ap.add_argument("--n_runs", type=int, default=16)
    ap.add_argument(
        "--n_sigma_zero", type=int, default=2, help="sigma_hi æ˜¾å¼ç½® 0 çš„ run æ•°é‡"
    )
    args = ap.parse_args()

    out_dir = args.output_dir
    out_dir.mkdir(parents=True, exist_ok=True)

    # 1) è‡ªåŠ¨é€‰ 5 æ ‹æ¥¼
    dataset_path = (
        Path(os.environ.get("BUILDINGS_BENCH", ""))
        if os.environ.get("BUILDINGS_BENCH")
        else None
    )
    selected = pick_five_buildings(out_dir, seed=args.random_seed)
    print("ğŸ“¦ é€‰ä¸­çš„ 5 æ ‹ï¼š", [f"{r['dataset']}:{r['building']}" for r in selected])

    # 2) ç”Ÿæˆ 16 ç»„ LHSï¼ˆå« sigma_hi çš„ log + zerosï¼‰
    plan_df = make_16runs_clrs_plan(
        seed=args.random_seed, n_runs=args.n_runs, n_sigma_zero=args.n_sigma_zero
    )
    plan_csv = out_dir / "clrs_sensitivity_plan_16runs.csv"
    plan_df.to_csv(plan_csv, index=False)
    print(f"ğŸ“ å·²å†™å‡º LHS è®¡åˆ’ï¼š{plan_csv}")

    # 3) é€ run Ã— æ¥¼ è¯„æµ‹
    all_rows = []
    per_building_files: Dict[Tuple[int, str], Path] = {}

    for run_id in plan_df["run_id"].tolist():
        run_dir = out_dir / f"run_{int(run_id):02d}"
        run_dir.mkdir(parents=True, exist_ok=True)
        print("\n" + "=" * 60)
        print(f"â–¶â–¶ å¼€å§‹ run {run_id} ...")

        for rec in selected:
            ds = rec["dataset"]
            bid = rec["building"]
            label = f"{ds}:{bid}"
            bdir = run_dir / label.replace(":", "_")

            out_csv = run_one_eval(
                evaluator_py=args.evaluator_py,
                baseline_ckpt=args.baseline_ckpt,
                dataset_name=ds,  # â† å…³é”®ï¼šå„è‡ªçš„æ•°æ®é›†
                building_id=bid,
                device=args.device,
                out_dir_for_building=bdir,
                plan_csv=plan_csv,
                lhs_run=int(run_id - 1),  # evaluator å†…æŒ‰ 0-based è¡Œç´¢å¼•
                context_len=args.context_len,
                pred_len=args.pred_len,
                batch_size=64 if not args.do_finetune else args.ft_batch_size,
                do_finetune=args.do_finetune,
                ft_batch_size=args.ft_batch_size,
            )

            if out_csv is None:
                val = np.nan
            else:
                try:
                    rec_df = pd.read_csv(out_csv).iloc[0]
                    val = float(rec_df["CVRMSE_168"])
                    per_building_files[(int(run_id), label)] = out_csv
                except Exception as e:
                    print(f"âš ï¸ è¯»å– {out_csv} å¤±è´¥ï¼š{e}")
                    val = np.nan

            all_rows.append(
                {"run_id": int(run_id), "building_id": label, "CVRMSE_168": val}
            )
    # 4) æ±‡æ€»è¡¨ï¼ˆé•¿è¡¨ â†’ å®½è¡¨ï¼‰
    long_df = pd.DataFrame(all_rows)
    long_csv = out_dir / "all_results_long.csv"
    long_df.to_csv(long_csv, index=False)
    print(f"\nâœ… å·²å†™å‡ºé•¿è¡¨ï¼š{long_csv}")

    wide_df = long_df.pivot_table(
        index="run_id", columns="building_id", values="CVRMSE_168", aggfunc="mean"
    )
    wide_df = wide_df.reindex(sorted(wide_df.index)).reset_index()
    # è¡Œå‡å€¼/æ–¹å·®
    val_cols = [c for c in wide_df.columns if c != "run_id"]
    wide_df["run_mean"] = wide_df[val_cols].mean(axis=1, skipna=True)
    wide_df["run_std"] = wide_df[val_cols].std(axis=1, ddof=1, skipna=True)

    wide_csv = out_dir / "all_results_wide.csv"
    wide_df.to_csv(wide_csv, index=False)
    print(f"âœ… å·²å†™å‡ºå®½è¡¨ï¼š{wide_csv}")

    # 5) ç»˜å›¾
    heatmap_png = out_dir / "heatmap_runs_x_buildings.png"
    plot_heatmap(wide_df[["run_id"] + val_cols + ["run_mean", "run_std"]], heatmap_png)
    print(f"ğŸ–¼  çƒ­åŠ›å›¾ï¼š{heatmap_png}")

    lines_dir = out_dir / "per_building_lines"
    lines_dir.mkdir(parents=True, exist_ok=True)
    plot_per_building_lines(wide_df[["run_id"] + val_cols], lines_dir)
    print(f"ğŸ–¼  æŠ˜çº¿å›¾ç›®å½•ï¼š{lines_dir}")

    # 6) è®°å½•ä¸€æ¬¡ config æ‘˜è¦
    summary = {
        "dataset_name": args.dataset_name,
        "buildings": selected,
        "n_runs": int(args.n_runs),
        "n_sigma_zero": int(args.n_sigma_zero),
        "context_len": int(args.context_len),
        "pred_len": int(args.pred_len),
        "device": args.device,
        "do_finetune": bool(args.do_finetune),
        "ft_batch_size": int(args.ft_batch_size),
        "baseline_ckpt": str(args.baseline_ckpt),
        "evaluator_py": str(args.evaluator_py),
        "plan_csv": str(plan_csv),
        "BUILDINGS_BENCH": os.environ.get("BUILDINGS_BENCH", ""),
    }
    with (out_dir / "run_summary.json").open("w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ§¾ è¿è¡Œæ‘˜è¦ï¼š{out_dir / 'run_summary.json'}")

    print("\nğŸ¯ å…¨éƒ¨å®Œæˆã€‚ä½ å¯ä»¥æŸ¥çœ‹ï¼š")
    print(f"  - LHS è®¡åˆ’ï¼š{plan_csv}")
    print(f"  - ç»“æœé•¿è¡¨ï¼š{long_csv}")
    print(f"  - ç»“æœå®½è¡¨ï¼š{wide_csv}")
    print(f"  - çƒ­åŠ›å›¾ï¼š  {heatmap_png}")
    print(f"  - æŠ˜çº¿å›¾ï¼š  {lines_dir}")


if __name__ == "__main__":
    main()
