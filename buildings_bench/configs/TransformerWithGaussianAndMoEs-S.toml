[model]
context_len = 168
pred_len = 24
num_encoder_layers = 2
num_decoder_layers = 2
nhead = 4
dim_feedforward = 512
d_model = 256
dropout = 0.0
# activation = 'gelu'
continuous_loads = true
ignore_spatial = false
continuous_head = 'gaussian_nll'
num_experts = 4
top_k = 2
# aux_loss_weight = 0.01
# num_groups = 2
# experts_per_gp = 2

[pretrain]
name = 'TransformerWithGaussianAndMoEs-S-Update-01'
batch_size = 2048
init_scale = 0.02
warmup_steps = 1250
lr = 0.00006
train_tokens = 1000000000
apply_scaler_transform = 'boxcox'

[zero_shot]
apply_scaler_transform = 'boxcox'

[transfer_learning]
apply_scaler_transform = 'boxcox'
