[model]
max_context_len = 336
max_pred_len = 168
context_len = 336
pred_len = 168 
continuous_loads = true
continuous_head = 'huber'

[pretrain]
batch_size = 32
init_scale = 0.02
warmup_steps = 10000
lr = 0.00006
train_tokens = 2000000000
eval_every = 200
apply_scaler_transform = 'boxcox'
note = ''

[transfer_learning]
ignore_scoring_rules = true
lr = 1e-3
max_epochs = 100
apply_scaler_transform = 'boxcox'