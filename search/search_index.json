{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to BuildingsBench","text":""},{"location":"#overview","title":"Overview","text":"<p>BuildingsBench is a platform for enabling</p> <ul> <li>Large-scale pretraining with energy timeseries using the synthetic Buildings-900K dataset, on a short-term load forecasting (STLF) task. Buildings-900K is statistically representative of the entire U.S. building stock and is extracted from the NREL End-Use Load Profiles database.</li> <li>Benchmarking such models on two tasks evaluating difficult generalization challenges: zero-shot STLF and transfer learning for STLF.</li> </ul> <p>We provide an index-based PyTorch Dataset for large-scale pretraining, easy data loading for multiple real building energy consumption datasets as PyTorch Tensors or Pandas DataFrames, from simple persistence to advanced transformer baselines, metrics management, a tokenizer based on KMeans for load time series, and more.</p> <p>Read more about BuildingsBench in our paper.</p>"},{"location":"#getting-started","title":"Getting started","text":""},{"location":"#installation","title":"Installation","text":"<p>If you aren't going to pretrain or evaluate models and just want access to the provided dataloaders, model code, metrics computation, etc., install the package with:</p> <pre><code>pip install buildings_bench\n</code></pre>"},{"location":"#full-installation","title":"Full installation","text":"<p>Otherwise, clone this repository and install it in editable mode in a virtual environment or a conda environment.</p> <ol> <li>Create an environment with <code>python&gt;=3.9</code>, for example: <code>conda create -n buildings_bench python=3.9</code>.</li> <li>Install the package in editable mode with <pre><code>git clone https://github.com/NREL/BuildingsBench.git\ncd BuildingsBench\npip install -e \".[benchmark]\"\n</code></pre></li> </ol>"},{"location":"#installing-faiss-gpu","title":"Installing faiss-gpu","text":"<p>Due to a PyPI limitation, we have to install <code>faiss-gpu</code> (for KMeans) by directly downloading the wheel from https://github.com/kyamagu/faiss-wheels/releases/. Download the wheel for the python version you are using, then install it in your environment.</p> <p>For example:</p> <pre><code>wget https://github.com/kyamagu/faiss-wheels/releases/download/v1.7.3/faiss_gpu-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n\npip install faiss_gpu-1.7.3-cp38-cp38-manylinux2014_x86_64.whl\n</code></pre>"},{"location":"#optional-installing-lightgbm","title":"[Optional] Installing LightGBM","text":"<p>If running the LightGBM baseline, you will need to install LightGBM.</p> <ol> <li>Follow instructions here for your OS. </li> <li>Then install <code>skforecast</code> with <code>pip install skforecast==0.8.1</code>.</li> </ol>"},{"location":"#environment-variables","title":"Environment variables","text":"<p>Set the environment variable <code>BUILDINGS_BENCH</code> to the path where the data directory <code>BuildingsBench</code> is located (created when untarring the data files). This is not the path to the code repository.</p> <pre><code>export BUILDINGS_BENCH=/path/to/BuildingsBench\n</code></pre>"},{"location":"#wandb","title":"Wandb","text":"<p>If using <code>wandb</code>, set the following:</p> <ul> <li><code>WANDB_ENTITY</code>: your wandb username</li> <li><code>WANDB_PROJECT</code>: the name of your wandb project for this benchmark</li> </ul>"},{"location":"#run-tests","title":"Run tests","text":"<p>Verify your installation by running unit tests:</p> <pre><code>python3 -m unittest\n</code></pre>"},{"location":"#next-steps","title":"Next steps","text":"<ol> <li>Download and get familiar with the datasets</li> <li>Learn how to download a pretrained model and run it on a building dataset</li> <li>Learn how to run a custom model on the benchmark</li> <li>Computing metrics and interpreting the results</li> </ol> <p>List of all tutorials.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use BuildingsBench in your research, please cite our preprint:</p> <pre><code>@article{emami2023buildingsbench,\n  title={Buildingsbench: A large-scale dataset of 900k buildings and benchmark for short-term load forecasting},\n  author={Emami, Patrick and Sahu, Abhijeet and Graf, Peter},\n  journal={Advances in Neural Information Processing Systems},\n  volume={36},\n  pages={19823--19857},\n  year={2023}\n}\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#datasets","title":"Datasets","text":""},{"location":"getting_started/#buildings-900k","title":"Buildings-900K","text":"<p>This is a dataset of energy timeseries derived from simulations of 900K building energy models. The timeseries are hourly and span an entire year. Each building energy model was simulated for two distinct weather years, so in total there are 1.8M timeseries. The weather timeseries and building metadata are also provided. </p>"},{"location":"getting_started/#buildingsbench-datasets","title":"BuildingsBench datasets","text":"<p>In our work, we used Buildings-900K for large-scale pretraining and the BuildingsBench real building datasets for zero-shot forecasting and transfer learning. The BuildingsBench benchmark is a collection of 7 datasets containing smart meter electricity timeseries of real, individual residential and commercial buildings. We also provide temperature timeseries that can be used to condition load forecasts.  </p>"},{"location":"getting_started/#accessing-the-data","title":"Accessing the data","text":"<p>The pretraining dataset and evaluation data is available for download here as tar files, or can be accessed via AWS S3 here. The benchmark datasets are &lt; 1GB in size in total and the pretraining data is ~110GB in size. </p> <p>The pretraining data is divided into 4 compressed files</p> <ul> <li><code>comstock_amy2018.tar.gz</code></li> <li><code>comstock_tmy3.tar.gz</code></li> <li><code>resstock_amy2018.tar.gz</code></li> <li><code>resstock_tmy3.tar.gz</code></li> </ul> <p>and one compressed file for the metadata</p> <ul> <li><code>metadata.tar.gz</code></li> </ul> <p>The evaluation datasets are compressed into a single file</p> <ul> <li><code>BuildingsBench.tar.gz</code></li> </ul> <p>Download all files to a folder on a storage device with at least 250GB of free space. Then, decompress all of the downloaded files. There will be a new subdirectory called <code>BuildingsBench</code>. This is the data directory, which is different than the Github code repository, although both folders are named \"BuildingsBench\".</p>"},{"location":"getting_started/#dataset-directory-organization","title":"Dataset directory organization","text":"<pre><code>BuildingsBench/\n\u251c\u2500\u2500 Buildings-900K/end-use-load-profiles-for-us-building-stock/2021/ # Buildings-900K pretraining data.\n    \u251c\u2500\u2500 comstock_amy2018_release_1/\n        \u251c\u2500\u2500 timeseries_individual_buildings/\n            \u251c\u2500\u2500 by_puma_midwest/\n                \u251c\u2500\u2500 upgrade=0/\n                    \u251c\u2500\u2500 puma={puma_id}/*.parquet\n                    \u251c\u2500\u2500 ...\n            \u251c\u2500\u2500 by_puma_northeast\n            \u251c\u2500\u2500 ...\n        \u251c\u2500\u2500 weather/\n            \u251c\u2500\u2500 {county_id}.csv\n            \u251c\u2500\u2500 ...\n        \u251c\u2500\u2500 metadata/ # Individual building simulation metadata.\n            \u251c\u2500\u2500 metadata.parquet\n    \u251c\u2500\u2500 ... # Other pretraining datasets (comstock_tmy3, resstock_amy2018, resstock_tmy3)            \n\u251c\u2500\u2500 BDG-2/ # Building Data Genome Project 2. This is real building smart meter data with outliers removed. \n    \u251c\u2500\u2500 {building_id}={year}.csv # The .csv files for the BDG-2 dataset,\n    \u251c\u2500\u2500 ... # Other buildings in BDG-2.\n    \u251c\u2500\u2500 weather_{building_id}.csv # Weather data for each building in BDG-2.\n\u251c\u2500\u2500 ... # Other evaluation datasets (Borealis, Electricity, etc.)\n\u251c\u2500\u2500 buildingsbench_with_outliers/ # Copy of the BuildingsBench smart meter data  *with outliers*\n\u251c\u2500\u2500 LICENSES/ # Licenses for each evaluation dataset redistributed in BuildingsBench. \n\u251c\u2500\u2500 metadata/ # Metadata for the evaluation suite.\n    \u251c\u2500\u2500 benchmark.toml # Metadata for the benchmark. For each dataset, we specify: `building_type`: `residential` or `commercial`, `latlon`: a List of two floats representing the location of the building(s), `conus_location`: The name of the county or city in the U.S. where the building is located, or a county/city in the U.S. of similar climate to the building's true location (N.b. we do not have nor provide the exact location of buildings), `actual_location`: The name of the county/city/country where the building is actually located which is different from `conus_location` when the building is located outside of CONUS (these values are for book-keeping and can be set to dummy values), `url`: The URL where the dataset was obtained from.\n    \u251c\u2500\u2500 building_years.txt # List of .csv files included in the benchmark. Each line is of the form `{dataset}/{building_id}={year}.csv`.\n    \u251c\u2500\u2500 withheld_pumas.tsv # List of PUMAs withheld from the training/validation set of Buildings-900K, which we use as synthetic test data.\n    \u251c\u2500\u2500 map_of_pumas_in_census_region*.csv # Maps PUMA IDs to their geographical centroid (lat/lon).\n    \u251c\u2500\u2500 spatial_tract_lookup_table.csv # Mapping between census tract identifiers and other geographies.\n    \u251c\u2500\u2500 list_oov.py # Python script to generate a list of buildings that are OOV for the Buildings-900K tokenizer.\n    \u251c\u2500\u2500 oov.txt # List of buildings that are OOV for the Buildings-900K tokenizer.\n    \u251c\u2500\u2500 transfer_learning_commercial_buildings.txt # List of 100 commercial buildings from the benchmark we use for evaluating transfer learning.\n    \u251c\u2500\u2500 transfer_learning_residential_buildings.txt # List of 100 residential buildings from the benchmark we use for evaluating transfer learning.\n    \u251c\u2500\u2500 transfer_learning_hyperparameter_tuning.txt # List of 2 held out buildings (1 commercial, 1 residential) that can be used for hyperparameter tuning.\n    \u251c\u2500\u2500 train*.idx # Index files for fast dataloading of Buildings-900K. This file uncompressed is ~16GB. \n    \u251c\u2500\u2500 val*.idx # Index files for fast dataloading of Buildings-900K.\n    \u251c\u2500\u2500 transforms # Directory for storing data transform info.\n        \u251c\u2500\u2500 weather/ # Directory where weather variable normalization parameters are stored.\n</code></pre>"},{"location":"getting_started/#dataset-updates","title":"Dataset Updates","text":"<ul> <li>Version 2.0.0:<ul> <li>Added the building simulation metadata files, which contain attributes for the EnergyPlus building energy model used to run the simulation. See <code>Buildings-900K/end-use-load-profiles-for-us-building-stock/2021/resstock_amy2018_release_1/metadata/metadata.parquet</code> for an example.</li> <li>Added weather timeseries data. See this description for more information.</li> </ul> </li> </ul>"},{"location":"getting_started/#buildings-900k-parquet-file-format","title":"Buildings-900K parquet file format","text":"<p>The pretraining dataset Buildings-900K is stored as a collection of parquet files. Each parquet file corresponds to a single PUMA, or Public Use Microdata Area, which is a geographic unit used by the U.S. Census Bureau. The parquet file contains the energy timeseries for all buildings assigned to that PUMA. Each PUMA-level parquet file in Buildings-900K is stored in a directory with a unique PUMA ID. For example, all residential buildings with weather-year <code>amy2018</code> in the northeast census region and PUMA ID <code>puma_id</code> can be found under: <code>Buildings-900K/end-use-load-profiles-for-us-building-stock/2021/resstock_amy2018_release_1/timeseries-individual-buildings/by_puma_northeast/upgrade=0/puma={puma_id}/*.parquet</code>. </p> <p>In the parquet file, the first column is the timestamp and each subsequent column is the energy consumption in kWh for a different building in that. These columns are named by building id. The timestamp is in the format <code>YYYY-MM-DD HH:MM:SS</code>. The energy consumption is in kWh. The parquet files are compressed with snappy. Sort by the timestamp after loading.</p> <pre><code>import pyarrow.parquet as pq\n\nbldg_id = '00001'\ndf = pq.read_table('puma={puma_id}', columns=['timestamp', bldg_id]).to_pandas().sort_values(by='timestamp')\n</code></pre>"},{"location":"getting_started/#exploring-the-data","title":"Exploring the data","text":"<p>See our dataset quick start Jupyter notebook</p>"},{"location":"getting_started/#csv-file-format","title":"CSV file format","text":"<p>We use a simpler CSV file format to store smart meter timeseries data for real buildings, which make up most of the data in the evaluation suite. Most CSV files in the benchmark are named <code>building_id=year.csv</code> and correspond to a single building's energy consumption time series. The first column is the timestamp (the Pandas index), and the second column is the energy consumption in kWh. The timestamp is in the format <code>YYYY-MM-DD HH:MM:SS</code>. The energy consumption is in kWh. </p> <p>Certain datasets have multiple buildings in a single file. In this case, the first column is the timestamp (the Pandas index), and each subsequent column is the energy consumption in kWh for a different building. These columns are named by building id. The timestamp is in the format <code>YYYY-MM-DD HH:MM:SS</code>. The energy consumption is in kWh.</p>"},{"location":"getting_started/#adding-a-new-dataset","title":"Adding a new dataset","text":"<p>For a new CSV dataset named <code>{dataset}</code></p> <ul> <li>Create a directory called  <code>{dataset}</code> of CSV files with filenames <code>{building_id}={year}.csv</code>.</li> <li>Add the line <code>{dataset}/{building_id}={year}.csv</code> for each file to the <code>building_years.txt</code> file.</li> <li>Add the appropriate metadata for the dataset to <code>benchmark.toml</code> under the <code>buildings_bench.{dataset}</code> tag.</li> <li>Add <code>{dataset}</code> to the benchmark registry in <code>buildings_bench/data/__init__.py</code>.</li> </ul> <p>You can now use the provided torch and pandas dataloaders to load this dataset by name <code>{dataset}</code>.</p>"},{"location":"getting_started/#out-of-vocab-test-consumption-values","title":"Out-of-vocab test consumption values","text":"<p>Hourly consumption values &gt; 5100 kWh are larger than the maximum values seen during pretraining on Buildings-900K. We consider these \"out-of-vocab\" and remove such buildings from evaluation.  This prevents errors due to extrapolation, which is not the focus of this benchmark. See <code>list_oov.py</code> for the code we use to generate a list of OOV buildings.</p>"},{"location":"running/","title":"Running the Benchmark","text":"<p>We provide scripts in the <code>./scripts</code> directory for pretraining and to run the benchmark tasks (zero-shot STLF and transfer learning), either with our provided baselines or your own model.</p> <p>PyTorch checkpoint files for our trained models are available for download as a single tar file  here or as individual files on S3 here.</p> <p>Our benchmark assumes each model takes as input a dictionary of torch tensors with the following keys:</p> <pre><code>{\n    'load': torch.Tensor,               # (batch_size, seq_len, 1)\n    'building_type': torch.LongTensor,  # (batch_size, seq_len, 1)\n    'day_of_year': torch.FloatTensor,   # (batch_size, seq_len, 1)\n    'hour_of_day': torch.FloatTensor,   # (batch_size, seq_len, 1)\n    'day_of_week': torch.FloatTensor,   # (batch_size, seq_len, 1)\n    'latitude': torch.FloatTensor,      # (batch_size, seq_len, 1)\n    'longitude': torch.FloatTensor,     # (batch_size, seq_len, 1)\n}\n</code></pre> <p>As of v2.0.0, models can also optionally take a <code>temperature</code> timeseries tensor as input. </p> <p>Arguments for each model are specified in a TOML configuration file in the <code>./buildings_bench/configs</code> directory. If you just want to modify the arguments for a provided model type, you can do so either by modifying the provided TOML config file or by creating a new TOML config file. To add your own custom model, you'll need to follow a few steps to register your model with our platform.</p>"},{"location":"running/#registering-your-model","title":"Registering your model","text":"<p>Please see this step-by-step tutorial for a Jupyter Notebook version of the following instructions.</p> <p>Make sure to have installed the benchmark in editable mode: <code>pip install -e .[benchmark]</code></p> <ol> <li>Create a file called <code>your_model.py</code> with your model's implementation, and make your model a subclass of the base model in <code>./buildings_bench/models/base_model.py</code>. Make sure to implement the abstract methods: <code>forward</code>, <code>loss</code>, <code>load_from_checkpoint</code>, <code>predict</code>, <code>unfreeze_and_get_parameters_for_finetuning</code>.</li> <li>Place this file under <code>./buildings_bench/models/your_model.py.</code></li> <li>Import your model class and add your model's name to the <code>model_registry</code> dictionary in <code>./buildings_bench/models/__init__.py</code>.</li> <li>Create a TOML config file under <code>./buildings_bench/configs/your_model.toml</code> with each keyword argument your model expects in its constructor (i.e., the hyperparameters for your model) and any additional args for the script you want to run.</li> </ol> <p>The TOML config file should look something like this:</p> <p><pre><code>[model]\n# your model's keyword arguments\n\n[pretrain]\n# override any of the default pretraining argparse args here\n\n[zero_shot]\n# override any of the default zero_shot argparse args here\n\n[transfer_learning]\n# override any of the default transfer_learning argparse args here\n</code></pre> See <code>./buildings_bench/configs/TransformerWithTokenizer-S.toml</code> for an example.</p>"},{"location":"running/#pretraining","title":"Pretraining","text":""},{"location":"running/#without-slurm","title":"Without SLURM","text":"<p>The script <code>pretrain.py</code> is implemented with PyTorch <code>DistributedDataParallel</code> so it must be launched with <code>torchrun</code> from the command line and the argument <code>--disable_slurm</code> must be passed. See <code>./scripts/pretrain.sh</code> for an example.</p> <pre><code>#!/bin/bash\n\nexport WORLD_SIZE=1\nNUM_GPUS=1\n\ntorchrun \\\n    --nnodes=1 \\\n    --nproc_per_node=$NUM_GPUS \\\n    --rdzv-backend=c10d \\\n    --rdzv-endpoint=localhost:0 \\\n    scripts/pretrain.py --model TransformerWithGaussian-S --disable_slurm\n</code></pre> <p>The argument <code>--disable_slurm</code> is not needed if you are running this script on a Slurm cluster as a batch job.</p> <p>This script will automatically log outputs to <code>wandb</code> if the environment variables <code>WANDB_ENTITY</code> and <code>WANDB_PROJECT</code> are set. Otherwise, pass the argument <code>--disable_wandb</code> to disable logging to <code>wandb</code>.</p>"},{"location":"running/#with-slurm","title":"With SLURM","text":"<p>To launch pretraining as a SLURM batch job:</p> <pre><code>export WORLD_SIZE=$(($SLURM_NNODES * $SLURM_NTASKS_PER_NODE))\necho \"WORLD_SIZE=\"$WORLD_SIZE\nexport MASTER_PORT=$(expr 10000 + $(echo -n $SLURM_JOBID | tail -c 4))\n\necho \"NODELIST=\"${SLURM_NODELIST}\nmaster_addr=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\nexport MASTER_ADDR=$master_addr\necho \"MASTER_ADDR=\"$MASTER_ADDR\n\nsrun python3 scripts/pretrain.py \\\n        --model TransformerWithGaussian-S\n</code></pre>"},{"location":"running/#zero-shot-evaluation","title":"Zero-shot Evaluation","text":"<p>The script <code>scripts/zero_shot.py</code> and the script for transfer learning <code>scripts/transfer_learning_torch.py</code> do not use <code>DistributedDataParallel</code> so they can be run without <code>torchrun</code>.</p> <p><code>python3 scripts/zero_shot.py --model TransformerWithGaussian-S --checkpoint /path/to/checkpoint.pt</code></p>"},{"location":"running/#transfer-learning-evaluation","title":"Transfer Learning Evaluation","text":"<p><code>python3 scripts/transfer_learning_torch.py --model TransformerWithGaussian-S --checkpoint /path/to/checkpoint.pt</code> </p>"},{"location":"running/#weather-timeseries","title":"Weather Timeseries","text":"<p>An important data source for forecasting building energy usage is the external weather condition. This significantly impacts energy usage in buildings, for example, when high temperatures lead to increases in cooling demand. In BuildingsBench v2.0.0, we have added weather timeseries data for each building in Buildings-900K and for each test building in the BuildingBench evaluation suite. In particular, we support pretraining and evaluation with a temperature timeseries input. The outdoor temperature is the most impactful weather feature for load forecasting. </p> <p>In detail, a forecasting model can be provided with both the past one week of temperature timeseries data as well as the temperature for the 24 hour prediction horizon. We note that some of the building datasets in our benchmark have more variables available beyond just temperature.</p> <p>Summary of available weather data: </p> <ul> <li> <p>Buildings-900K weather: For each PUMA and year (<code>amy2018</code>, <code>tmy3</code>), there is a corresponding weather csv file. That is, a residential building in the same PUMA has the same <code>amy2018</code> weather timeseries as a commercial building in that PUMA for <code>amy2018</code>. This file has hourly annual weather data with the following 7 variables: Dry Bulb Temperature (\u00b0C), Relative Humidity (%), Wind Speed (m/s), Wind Direction (Deg),Global Horizontal Radiation (W/m2), Direct Normal Radiation (W/m2), Diffuse Horizontal Radiation (W/m2). We note that these weather files are the same ones used by the EnergyPlus simulator to create these synthetic load timeseries. </p> </li> <li> <p>BDG-2 and SMART datasets weather: These datasets provide per-building hourly temperature and humidity timeseries, which we include.  </p> </li> <li> <p>Other BuildingsBench evaluation datasets: The Electricity, Borealis, IDEAL, LCL, Sceaux do not provide weather data. We collected the temperature timeseries ourselves from the National Oceanic and Atmospheric Administration's (NOAA) Integrated Surface Database (ISD), managed by the National Centers for Environmental Information (NCEI).  </p> </li> </ul> <p>An important caveat is that we are not using 24-hour weather forecasts as inputs to our load forecasting model. Rather, we are providing the models with the actual day-ahead weather that was recorded. In reality, we do not know tomorrow's weather and so our models must normally rely on a (potentially inaccurate) weather forecast. </p>"},{"location":"running/#training-and-evaluation-with-weather-data","title":"Training and evaluation with weather data","text":"<p>To train or evaluate a model that uses temperature timeseries inputs, create a new model configuration TOML file in the <code>buildings_bench/configs</code> folder to include the <code>weather_inputs</code> key:</p> <pre><code>[model]\n\nweather_inputs = ['temperature']\n</code></pre> <p>The <code>weather_inputs</code> key is a list of strings that correspond to the weather variables you want to include in your model and load from the corresponding datasets. </p> <p>This will automatically add keys to the model's batch dictionary with the same names as the weather variables:</p> <pre><code>{\n    'load': torch.Tensor,               # (batch_size, seq_len, 1)\n    'building_type': torch.LongTensor,  # (batch_size, seq_len, 1)\n    'day_of_year': torch.FloatTensor,   # (batch_size, seq_len, 1)\n    'hour_of_day': torch.FloatTensor,   # (batch_size, seq_len, 1)\n    'day_of_week': torch.FloatTensor,   # (batch_size, seq_len, 1)\n    'latitude': torch.FloatTensor,      # (batch_size, seq_len, 1)\n    'longitude': torch.FloatTensor,     # (batch_size, seq_len, 1)\n    'temperature': torch.FloatTensor,   # (batch_size, seq_len, 1)\n}\n</code></pre> <p>Then, launch model training in the usual way: </p> <pre><code>export WORLD_SIZE=1\n\ntorchrun \\\n    --nnodes=1 \\\n    --nproc_per_node=1 \\\n    --rdzv-backend=c10d \\\n    --rdzv-endpoint=localhost:0 \\\n    scripts/pretrain.py \\\n    --model TransformerWithGaussian-t-S \\\n    --disable_slurm\n</code></pre> <p>We provide default small (S), medium (M), and large (L) model configs for models that expect <code>temperature</code> timeseries inputs: <code>TransformerWithGaussian-t-*</code>, <code>temperature</code> and <code>humidity</code> inputs: <code>TransformerWithGaussian-th-*</code>, and all available weather variables for the synthetic Buildings-900K data: <code>TransformerWithGaussian-weather-*</code>.</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Links to Jupyter Notebooks hosted on Github: </p> <ul> <li>Dataset quick start</li> <li>Running pretrained models</li> <li>Register a new model with BuildingsBench</li> <li>Compute aggregate statistics from results files</li> </ul>"},{"location":"API/data/buildings_bench-data/","title":"buildings_bench.data","text":"<p>Functions and class definitions for loading Torch and Pandas datasets.</p> <p>Main entry points for loading PyTorch and Pandas datasets:</p> <ul> <li><code>load_pretraining()</code> (used for pretraining)</li> <li><code>load_torch_dataset()</code> (used for benchmark tasks)</li> <li><code>load_pandas_dataset()</code> (used for benchmark tasks)</li> </ul> <p>Available PyTorch Datasets:</p> <ul> <li><code>Buildings900K</code> (used for pretraining)</li> <li><code>TorchBuildingsDataset</code> (used for benchmark tasks)</li> <li><code>PandasTransformerDataset</code> (used for benchmark tasks)</li> </ul>"},{"location":"API/data/buildings_bench-data/#load_pretraining","title":"load_pretraining","text":""},{"location":"API/data/buildings_bench-data/#buildings_bench.data.load_pretraining","title":"<code>buildings_bench.data.load_pretraining(name, num_buildings_ablation=-1, apply_scaler_transform='', scaler_transform_path=None, weather_inputs=None, custom_idx_filename='', context_len=168, pred_len=24)</code>","text":"<p>Pre-training datasets: buildings-900k-train, buildings-900k-val</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the dataset to load.</p> required <code>num_buildings_ablation</code> <code>int</code> <p>Number of buildings to use for pre-training.                             If -1, use all buildings.</p> <code>-1</code> <code>apply_scaler_transform</code> <code>str</code> <p>If not using quantized load or unscaled loads,                      applies a {boxcox,standard} scaling transform to the load. Default: ''.</p> <code>''</code> <code>scaler_transform_path</code> <code>Path</code> <p>Path to data for transform, e.g., pickled data for BoxCox transform.</p> <code>None</code> <code>weather_inputs</code> <code>List[str]</code> <p>list of weather feature names to use as additional inputs. Default: None.</p> <code>None</code> <code>custom_idx_filename</code> <code>str</code> <p>customized index filename. Default: ''</p> <code>''</code> <code>context_len</code> <code>int</code> <p>Length of the context. Defaults to 168.</p> <code>168</code> <code>pred_len</code> <code>int</code> <p>Length of the prediction horizon. Defaults to 24.</p> <code>24</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>torch.utils.data.Dataset: Dataset for pretraining.</p>"},{"location":"API/data/buildings_bench-data/#load_torch_dataset","title":"load_torch_dataset","text":""},{"location":"API/data/buildings_bench-data/#buildings_bench.data.load_torch_dataset","title":"<code>buildings_bench.data.load_torch_dataset(name, dataset_path=None, apply_scaler_transform='', scaler_transform_path=None, weather_inputs=None, include_outliers=False, context_len=168, pred_len=24)</code>","text":"<p>Load datasets by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the dataset to load.</p> required <code>dataset_path</code> <code>Path</code> <p>Path to the benchmark data. Optional.</p> <code>None</code> <code>apply_scaler_transform</code> <code>str</code> <p>If not using quantized load or unscaled loads,                      applies a {boxcox,standard} scaling transform to the load. Default: ''.</p> <code>''</code> <code>scaler_transform_path</code> <code>Path</code> <p>Path to data for transform, e.g., pickled data for BoxCox transform.</p> <code>None</code> <code>weather_inputs</code> <code>List[str]</code> <p>list of weather feature names to use as additional inputs. Default: None.</p> <code>None</code> <code>include_outliers</code> <code>bool</code> <p>Use version of BuildingsBench with outliers.</p> <code>False</code> <code>context_len</code> <code>int</code> <p>Length of the context. Defaults to 168.</p> <code>168</code> <code>pred_len</code> <code>int</code> <p>Length of the prediction horizon. Defaults to 24.</p> <code>24</code> <p>Returns:</p> Name Type Description <code>dataset</code> <code>Union[TorchBuildingDatasetsFromCSV, TorchBuildingDatasetFromParquet]</code> <p>Dataset for benchmarking.</p>"},{"location":"API/data/buildings_bench-data/#load_pandas_dataset","title":"load_pandas_dataset","text":""},{"location":"API/data/buildings_bench-data/#buildings_bench.data.load_pandas_dataset","title":"<code>buildings_bench.data.load_pandas_dataset(name, dataset_path=None, feature_set='engineered', weather_inputs=None, apply_scaler_transform='', scaler_transform_path=None, include_outliers=False)</code>","text":"<p>Load datasets by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the dataset to load.</p> required <code>dataset_path</code> <code>Path</code> <p>Path to the benchmark data. Optional.</p> <code>None</code> <code>feature_set</code> <code>str</code> <p>Feature set to use. Default: 'engineered'.</p> <code>'engineered'</code> <code>weather_inputs</code> <code>List[str]</code> <p>list of weather feature names to use as additional inputs. Default: None.</p> <code>None</code> <code>apply_scaler_transform</code> <code>str</code> <p>If not using quantized load or unscaled loads,                         applies a {boxcox,standard} scaling transform to the load. Default: ''. </p> <code>''</code> <code>scaler_transform_path</code> <code>Path</code> <p>Path to data for transform, e.g., pickled data for BoxCox transform.</p> <code>None</code> <code>include_outliers</code> <code>bool</code> <p>Use version of BuildingsBench with outliers.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dataset</code> <code>PandasBuildingDatasetsFromCSV</code> <p>Generator of Pandas datasets for benchmarking.</p>"},{"location":"API/data/buildings_bench-data/#the-buildings-900k-pytorch-dataset","title":"The Buildings-900K PyTorch Dataset","text":""},{"location":"API/data/buildings_bench-data/#buildings_bench.data.buildings900K.Buildings900K","title":"<code>buildings_bench.data.buildings900K.Buildings900K</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>This is an indexed dataset for the Buildings-900K dataset. It uses an index file to quickly load a sub-sequence from a time series in a multi-building Parquet file. The index file is a tab separated file with the following columns:</p> <ol> <li>Building-type-and-year (e.g., comstock_tmy3_release_1)</li> <li>Census region (e.g., by_puma_midwest)</li> <li>PUMA ID</li> <li>Building ID</li> <li>Hour of year pointer (e.g., 0070)</li> </ol> <p>The sequence pointer is used to extract the slice [pointer - context length : pointer + pred length] for a given building ID.</p> <p>The time series are not stored chronologically and must be sorted by timestamp after loading.</p> <p>Each dataloader worker has its own file pointer to the index file. This is to avoid weird multiprocessing errors from sharing a file pointer. We 'seek' to the correct line in the index file for random access.</p>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.buildings900K.Buildings900K.__init__","title":"<code>__init__(dataset_path, index_file, context_len=168, pred_len=24, apply_scaler_transform='', scaler_transform_path=None, weather_inputs=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>Path</code> <p>Path to the pretraining dataset.</p> required <code>index_file</code> <code>str</code> <p>Name of the index file</p> required <code>context_len</code> <code>int</code> <p>Length of the context. Defaults to 168.  The index file has to be generated with the same context length.</p> <code>168</code> <code>pred_len</code> <code>int</code> <p>Length of the prediction horizon. Defaults to 24. The index file has to be generated with the same pred length.</p> <code>24</code> <code>apply_scaler_transform</code> <code>str</code> <p>Apply a scaler transform to the load. Defaults to ''.</p> <code>''</code> <code>scaler_transform_path</code> <code>Path</code> <p>Path to the scaler transform. Defaults to None.</p> <code>None</code> <code>weather_inputs</code> <code>List[str]</code> <p>list of weather features to use. Default: None.</p> <code>None</code>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.buildings900K.Buildings900K.__read_index_file","title":"<code>__read_index_file(index_file)</code>","text":"<p>Extract metadata from index file.</p>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.buildings900K.Buildings900K.collate_fn","title":"<code>collate_fn()</code>","text":"<p>Returns a function taking only one argument (the list of items to be batched).</p>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.buildings900K.Buildings900K.init_fp","title":"<code>init_fp()</code>","text":"<p>Each worker needs to open its own file pointer to avoid  weird multiprocessing errors from sharing a file pointer.</p> <p>This is not called in the main process. This is called in the DataLoader worker_init_fn. The file is opened in binary mode which lets us disable buffering.</p>"},{"location":"API/data/buildings_bench-data/#torchbuildingdataset","title":"TorchBuildingDataset","text":""},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.TorchBuildingDataset","title":"<code>buildings_bench.data.datasets.TorchBuildingDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>PyTorch Dataset for a single building's energy timeseries (a Pandas Dataframe)   with a timestamp index and a <code>power</code> column.</p> <p>Used to iterate over mini-batches of 192-hour timeseries (168 hours of context, 24 hours prediction horizon).</p>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.TorchBuildingDataset.__init__","title":"<code>__init__(dataframe, building_latlon, building_type, context_len=168, pred_len=24, sliding_window=24, apply_scaler_transform='', scaler_transform_path=None, is_leap_year=False, weather_dataframe=None, weather_transform_path=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>Pandas DataFrame with a timestamp index and a 'power' column.</p> required <code>building_latlon</code> <code>List[float]</code> <p>Latitude and longitude of the building.</p> required <code>building_type</code> <code>BuildingTypes</code> <p>Building type for the dataset.</p> required <code>context_len</code> <code>int</code> <p>Length of context. Defaults to 168.</p> <code>168</code> <code>pred_len</code> <code>int</code> <p>Length of prediction. Defaults to 24.</p> <code>24</code> <code>sliding_window</code> <code>int</code> <p>Stride for sliding window to split timeseries into test samples. Defaults to 24.</p> <code>24</code> <code>apply_scaler_transform</code> <code>str</code> <p>Apply scaler transform {boxcox,standard} to the load. Defaults to ''.</p> <code>''</code> <code>scaler_transform_path</code> <code>Path</code> <p>Path to the pickled data for BoxCox transform. Defaults to None.</p> <code>None</code> <code>is_leap_year</code> <code>bool</code> <p>Is the year a leap year? Defaults to False.</p> <code>False</code> <code>weather_dataframe</code> <code>DataFrame</code> <p>Weather timeseries data. Defaults to None.</p> <code>None</code> <code>weather_transform_path</code> <code>Path</code> <p>Path to the pickled data for weather transform. Defaults to None.</p> <code>None</code>"},{"location":"API/data/buildings_bench-data/#pandastransformerdataset","title":"PandasTransformerDataset","text":""},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.PandasTransformerDataset","title":"<code>buildings_bench.data.datasets.PandasTransformerDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Create a Torch Dataset from a Pandas DataFrame.</p> <p>Used to iterate over mini-batches of e.g, 192-hour (168 hours context + 24 hour pred horizon) timeseries.</p>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.PandasTransformerDataset.__init__","title":"<code>__init__(df, context_len=168, pred_len=24, sliding_window=24, weather_inputs=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Pandas DataFrame with columns: load, latitude, longitude, hour of day, day of week, day of year, building type</p> required <code>context_len</code> <code>int</code> <p>Length of context.. Defaults to 168.</p> <code>168</code> <code>pred_len</code> <code>int</code> <p>Length of prediction sequence for the forecasting model. Defaults to 24.</p> <code>24</code> <code>sliding_window</code> <code>int</code> <p>Stride for sliding window to split timeseries into test samples. Defaults to 24.</p> <code>24</code> <code>weather_inputs</code> <code>List[str]</code> <p>list of weather feature names to use as additional inputs. Defaults to None. The df is assumed to already have the weather inputs in the list as columns.</p> <code>None</code>"},{"location":"API/data/buildings_bench-data/#torchbuildingdatasetsfromparquet","title":"TorchBuildingDatasetsFromParquet","text":""},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.TorchBuildingDatasetFromParquet","title":"<code>buildings_bench.data.datasets.TorchBuildingDatasetFromParquet</code>","text":"<p>Generate PyTorch Datasets out of EULP parquet files.</p> <p>Each file has multiple buildings (with same Lat/Lon and building type) and each building is a column. All time series are for the same year.     </p> <p>Attributes:</p> Name Type Description <code>building_datasets</code> <code>dict</code> <p>Maps unique building ids to a TorchBuildingDataset.</p>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.TorchBuildingDatasetFromParquet.__init__","title":"<code>__init__(data_path, parquet_datasets, building_latlons, building_types, weather_inputs=None, context_len=168, pred_len=24, sliding_window=24, apply_scaler_transform='', scaler_transform_path=None, leap_years=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Path</code> <p>Path to the dataset</p> required <code>parquet_datasets</code> <code>List[str]</code> <p>List of paths to a parquet file, each has a timestamp index and multiple columns, one per building.</p> required <code>building_latlons</code> <code>List[List[float]]</code> <p>List of latlons for each parquet file.</p> required <code>building_types</code> <code>List[BuildingTypes]</code> <p>List of building types for each parquet file.</p> required <code>weather_inputs</code> <code>List[str]</code> <p>list of weather feature names to use as additional inputs. Default: None.</p> <code>None</code> <code>context_len</code> <code>int</code> <p>Length of context. Defaults to 168.</p> <code>168</code> <code>pred_len</code> <code>int</code> <p>Length of prediction. Defaults to 24.</p> <code>24</code> <code>sliding_window</code> <code>int</code> <p>Stride for sliding window to split timeseries into test samples. Defaults to 24.</p> <code>24</code> <code>apply_scaler_transform</code> <code>str</code> <p>Apply scaler transform {boxcox,standard} to the load. Defaults to ''.</p> <code>''</code> <code>scaler_transform_path</code> <code>Path</code> <p>Path to the pickled data for BoxCox transform. Defaults to None.</p> <code>None</code> <code>leap_years</code> <code>List[int]</code> <p>List of leap years. Defaults to None.</p> <code>None</code>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.TorchBuildingDatasetFromParquet.__iter__","title":"<code>__iter__()</code>","text":"<p>Generator to iterate over the building datasets.</p> <p>Yields:</p> Type Description <code>Tuple[str, TorchBuildingDataset]</code> <p>A pair of building id, TorchBuildingDataset objects.</p>"},{"location":"API/data/buildings_bench-data/#torchbuildingdatasetsfromcsv","title":"TorchBuildingDatasetsFromCSV","text":""},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.TorchBuildingDatasetsFromCSV","title":"<code>buildings_bench.data.datasets.TorchBuildingDatasetsFromCSV</code>","text":"<p>TorchBuildingDatasetsFromCSV</p> <p>Generate PyTorch Datasets from a list of CSV files.</p> <p>Attributes:</p> Name Type Description <code>building_datasets</code> <code>dict</code> <p>Maps unique building ids to a list of tuples (year, TorchBuildingDataset).</p>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.TorchBuildingDatasetsFromCSV.__init__","title":"<code>__init__(data_path, building_year_files, building_latlon, building_type, weather_inputs=None, context_len=168, pred_len=24, sliding_window=24, apply_scaler_transform='', scaler_transform_path=None, leap_years=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Path</code> <p>Path to the dataset</p> required <code>building_year_files</code> <code>List[str]</code> <p>List of paths to a csv file, each has a timestamp index and multiple columns, one per building.</p> required <code>building_type</code> <code>BuildingTypes</code> <p>Building type for the dataset.</p> required <code>weather_inputs</code> <code>List[str]</code> <p>list of weather feature names to use as additional inputs. Defaults to None.</p> <code>None</code> <code>context_len</code> <code>int</code> <p>Length of context. Defaults to 168.</p> <code>168</code> <code>pred_len</code> <code>int</code> <p>Length of prediction sequence for the forecasting model. Defaults to 24.</p> <code>24</code> <code>sliding_window</code> <code>int</code> <p>Stride for sliding window to split timeseries into test samples. Defaults to 24.</p> <code>24</code> <code>apply_scaler_transform</code> <code>str</code> <p>Apply scaler transform {boxcox,standard} to the load. Defaults to ''.</p> <code>''</code> <code>scaler_transform_path</code> <code>Path</code> <p>Path to the pickled data for BoxCox transform. Defaults to None.</p> <code>None</code> <code>leap_years</code> <code>List[int]</code> <p>List of leap years. Defaults to None.</p> <code>None</code>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.TorchBuildingDatasetsFromCSV.__iter__","title":"<code>__iter__()</code>","text":"<p>A Generator for TorchBuildingDataset objects.</p> <p>Yields:</p> Type Description <code>Tuple[str, ConcatDataset]</code> <p>A tuple of the building id and a ConcatDataset of the TorchBuildingDataset objects for all years.</p>"},{"location":"API/data/buildings_bench-data/#pandasbuildingdatasetsfromcsv","title":"PandasBuildingDatasetsFromCSV","text":""},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.PandasBuildingDatasetsFromCSV","title":"<code>buildings_bench.data.datasets.PandasBuildingDatasetsFromCSV</code>","text":"<p>Generate Pandas Dataframes from a list of CSV files.</p> <p>Can be used with sklearn models or tree-based models that require Pandas Dataframes. In this case, use 'features' = 'engineered' to generate a dataframe with engineered features.</p> <p>Create a dictionary of building datasets from a list of csv files. Used as a generator to iterate over Pandas Dataframes for each building. The Pandas Dataframe contain all of the years of data for the building.</p> <p>Attributes:</p> Name Type Description <code>building_datasets</code> <code>dict</code> <p>Maps unique building ids to a list of tuples (year, Dataframe).</p>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.PandasBuildingDatasetsFromCSV.__init__","title":"<code>__init__(data_path, building_year_files, building_latlon, building_type, weather_inputs=None, features='transformer', apply_scaler_transform='', scaler_transform_path=None, leap_years=[])</code>","text":"<p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Path</code> <p>Path to the dataset</p> required <code>building_year_files</code> <code>List[str]</code> <p>List of paths to a csv file, each has a timestamp index and multiple columns, one per building.</p> required <code>building_type</code> <code>BuildingTypes</code> <p>Building type for the dataset.</p> required <code>weather_inputs</code> <code>List[str]</code> <p>list of weather feature names to use as additional inputs. Defaults to None.</p> <code>None</code> <code>features</code> <code>str</code> <p>Type of features to use. Defaults to 'transformer'. {'transformer','engineered'} 'transformer' features: load, latitude, longitude, hour of day, day of week, day of year, building type 'engineered' features are an expansive list of mainly calendar-based features, useful for traditional ML models.</p> <code>'transformer'</code> <code>apply_scaler_transform</code> <code>str</code> <p>Apply scaler transform {boxcox,standard} to the load. Defaults to ''.</p> <code>''</code> <code>scaler_transform_path</code> <code>Path</code> <p>Path to the pickled data for BoxCox transform. Defaults to None.</p> <code>None</code> <code>leap_years</code> <code>List[int]</code> <p>List of leap years. Defaults to None.</p> <code>[]</code>"},{"location":"API/data/buildings_bench-data/#buildings_bench.data.datasets.PandasBuildingDatasetsFromCSV.__iter__","title":"<code>__iter__()</code>","text":"<p>Generator for iterating over the dataset.</p> <p>Yields:</p> Type Description <code>Tuple[str, DataFrame]</code> <p>A pair of building id and Pandas dataframe.  The dataframe has all years concatenated.</p>"},{"location":"API/models/buildings_bench-models/","title":"buildings_bench.models","text":"<p>Available models:</p> <ul> <li>Encoder-decoder time series transformer</li> <li>Persistence Ensemble (<code>AveragePersistence</code>)</li> <li>Previous Day Persistence (<code>CopyLastDayPersistence</code>)</li> <li>Previous Week Persistence (<code>CopyLastWeekPersistence</code>)</li> <li>Linear regression</li> <li>DLinear</li> </ul> <p>Main entry point for loading a BuildingsBench model is <code>model_factory()</code>.</p>"},{"location":"API/models/buildings_bench-models/#model_factory","title":"model_factory","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.model_factory","title":"<code>buildings_bench.models.model_factory(model_name, model_args)</code>","text":"<p>Instantiate and returns a model for the benchmark.</p> <p>Returns the model itself, the loss function to use, and the predict function.</p> <p>The predict function should return a tuple of two tensors:  (point predictions, prediction distribution parameters) where the distribution parameters may be, e.g., logits, or mean and variance.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Name of the model.</p> required <code>model_args</code> <code>Dict</code> <p>The keyword arguments for the model.</p> required <p>Returns:     model (torch.nn.Module): the instantiated model     loss (Callable): loss function     predict (Callable): predict function</p>"},{"location":"API/models/buildings_bench-models/#basemodel","title":"BaseModel","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.base_model.BaseModel","title":"<code>buildings_bench.models.base_model.BaseModel</code>","text":"<p>               Bases: <code>Module</code>, <code>PyTorchModelHubMixin</code></p> <p>Base class for all models.</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.base_model.BaseModel.__init__","title":"<code>__init__(context_len, pred_len, continuous_loads)</code>","text":"<p>Init method for BaseModel.</p> <p>Parameters:</p> Name Type Description Default <code>context_len</code> <code>int</code> <p>length of context window</p> required <code>pred_len</code> <code>int</code> <p>length of prediction window</p> required <code>continuous_loads</code> <code>bool</code> <p>whether to use continuous load values</p> required"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.base_model.BaseModel.forward","title":"<code>forward(x)</code>  <code>abstractmethod</code>","text":"<p>Forward pass. </p> <p>Expected keys in x:</p> <pre><code>- 'load': torch.Tensor of shape (batch_size, seq_len, 1)\n- 'building_type': torch.LongTensor of shape (batch_size, seq_len, 1)\n- 'day_of_year': torch.FloatTensor of shape (batch_size, seq_len, 1)\n- 'hour_of_day': torch.FloatTensor of shape (batch_size, seq_len, 1)\n- 'day_of_week': torch.FloatTensor of shape (batch_size, seq_len, 1)\n- 'latitude': torch.FloatTensor of shape (batch_size, seq_len, 1)\n- 'longitude': torch.FloatTensor of shape (batch_size, seq_len, 1)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Dict</code> <p>dictionary of input tensors</p> required <p>Returns:     predictions, distribution parameters (Tuple[torch.Tensor, torch.Tensor]): outputs</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.base_model.BaseModel.load_from_checkpoint","title":"<code>load_from_checkpoint(checkpoint_path)</code>  <code>abstractmethod</code>","text":"<p>Describes how to load the model from checkpoint_path.</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.base_model.BaseModel.loss","title":"<code>loss(x, y)</code>  <code>abstractmethod</code>","text":"<p>A function for computing the loss.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>preds of shape (batch_size, seq_len, 1)</p> required <code>y</code> <code>Tensor</code> <p>targets of shape (batch_size, seq_len, 1)</p> required <p>Returns:     loss (torch.Tensor): scalar loss</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.base_model.BaseModel.predict","title":"<code>predict(x)</code>  <code>abstractmethod</code>","text":"<p>A function for making a forecast on x with the model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Dict</code> <p>dictionary of input tensors</p> required <p>Returns:     predictions (torch.Tensor): of shape (batch_size, pred_len, 1)     distribution_parameters (torch.Tensor): of shape (batch_size, pred_len, -1)</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.base_model.BaseModel.unfreeze_and_get_parameters_for_finetuning","title":"<code>unfreeze_and_get_parameters_for_finetuning()</code>  <code>abstractmethod</code>","text":"<p>For transfer learning. </p> <ul> <li>Set requires_grad=True for parameters being fine-tuned (if necessary)</li> <li>Return the parameters that should be fine-tuned.</li> </ul>"},{"location":"API/models/buildings_bench-models/#loadforecastingtransformer","title":"LoadForecastingTransformer","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.LoadForecastingTransformer","title":"<code>buildings_bench.models.transformers.LoadForecastingTransformer</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>An encoder-decoder time series Transformer. Based on PyTorch nn.Transformer.</p> <ul> <li>Uses masking in the decoder to prevent the model from peeking into the future</li> <li>Uses N(0, 0.02) for weight initialization</li> <li>Trains with teacher forcing (i.e. the target is used as the input to the decoder)</li> <li>continuous_loads (True) just predict target values                  (False) categorical over quantized load values</li> </ul>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.LoadForecastingTransformer.__init__","title":"<code>__init__(context_len=168, pred_len=24, vocab_size=2274, num_encoder_layers=3, num_decoder_layers=3, d_model=256, nhead=8, dim_feedforward=256, dropout=0.0, activation='gelu', continuous_loads=False, continuous_head='mse', ignore_spatial=False, weather_inputs=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>context_len</code> <code>int</code> <p>length of the input sequence.</p> <code>168</code> <code>pred_len</code> <code>int</code> <p>length of the output sequence.</p> <code>24</code> <code>vocab_size</code> <code>int</code> <p>number of quantized load values in the entire vocabulary.</p> <code>2274</code> <code>num_encoder_layers</code> <code>int</code> <p>number of encoder layers.</p> <code>3</code> <code>num_decoder_layers</code> <code>int</code> <p>number of decoder layers.</p> <code>3</code> <code>d_model</code> <code>int</code> <p>number of expected features in the encoder/decoder inputs.</p> <code>256</code> <code>nhead</code> <code>int</code> <p>number of heads in the multi-head attention models.</p> <code>8</code> <code>dim_feedforward</code> <code>int</code> <p>dimension of the feedforward network model.</p> <code>256</code> <code>dropout</code> <code>float</code> <p>dropout value.</p> <code>0.0</code> <code>activation</code> <code>str</code> <p>the activation function of encoder/decoder intermediate layer, relu or gelu.</p> <code>'gelu'</code> <code>continuous_loads</code> <code>bool</code> <p>whether inputs are continuous/to train the model to predict continuous values.</p> <code>False</code> <code>continuous_head</code> <code>str</code> <p>'mse' or 'gaussian_nll'.</p> <code>'mse'</code> <code>ignore_spatial</code> <code>bool</code> <p>whether to ignore the spatial features.</p> <code>False</code> <code>weather_inputs</code> <code>List[str]</code> <p>list of weather features to use. Default: None.</p> <code>None</code>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.LoadForecastingTransformer.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the time series transformer. </p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Dict</code> <p>dictionary of input tensors.</p> required <p>Returns:     logits (torch.Tensor): [batch_size, pred_len, vocab_size] if not continuous_loads,                            [batch_size, pred_len, 1] if continuous_loads and continuous_head == 'mse',                             [batch_size, pred_len, 2] if continuous_loads and continuous_head == 'gaussian_nll'.</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.LoadForecastingTransformer.generate_sample","title":"<code>generate_sample(x, temperature=1.0, greedy=False, num_samples=1)</code>","text":"<p>Sample from the conditional distribution.</p> <p>Use output of decoder at each prediction step as input to the next decoder step. Implements greedy decoding and random temperature-controlled sampling.</p> <p>Top-k sampling and nucleus sampling are deprecated.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Dict</code> <p>dictionary of input tensors</p> required <code>temperature</code> <code>float</code> <p>temperature for sampling</p> <code>1.0</code> <code>greedy</code> <code>bool</code> <p>whether to use greedy decoding</p> <code>False</code> <code>num_samples</code> <code>int</code> <p>number of samples to generate</p> <code>1</code> <p>Returns:</p> Name Type Description <code>predictions</code> <code>Tensor</code> <p>of shape [batch_size, pred_len, 1] or shape [batch_size, num_samples, pred_len] if num_samples &gt; 1.</p> <code>distribution_parameters</code> <code>Tensor</code> <p>of shape [batch_size, pred_len, 1]. Not returned if sampling.</p>"},{"location":"API/models/buildings_bench-models/#tokenembedding","title":"TokenEmbedding","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.TokenEmbedding","title":"<code>buildings_bench.models.transformers.TokenEmbedding</code>","text":"<p>               Bases: <code>Module</code></p> <p>Helper Module to convert tensor of input indices into corresponding tensor of token embeddings.</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.TokenEmbedding.__init__","title":"<code>__init__(vocab_size, emb_size)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>vocab_size</code> <code>int</code> <p>number of quantized load values in the entire vocabulary.</p> required <code>emb_size</code> <code>int</code> <p>embedding size.</p> required"},{"location":"API/models/buildings_bench-models/#positionalencoding","title":"PositionalEncoding","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.PositionalEncoding","title":"<code>buildings_bench.models.transformers.PositionalEncoding</code>","text":"<p>               Bases: <code>Module</code></p> <p>Helper Module that adds positional encoding to the token embedding to introduce a notion of order within a time-series.</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.PositionalEncoding.__init__","title":"<code>__init__(emb_size, dropout, maxlen=500)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>emb_size</code> <code>int</code> <p>embedding size.</p> required <code>dropout</code> <code>float</code> <p>dropout rate.</p> required <code>maxlen</code> <code>int</code> <p>maximum possible length of the incoming time series.</p> <code>500</code>"},{"location":"API/models/buildings_bench-models/#timeseriessinusoidalperiodicembedding","title":"TimeSeriesSinusoidalPeriodicEmbedding","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.TimeSeriesSinusoidalPeriodicEmbedding","title":"<code>buildings_bench.models.transformers.TimeSeriesSinusoidalPeriodicEmbedding</code>","text":"<p>               Bases: <code>Module</code></p> <p>This module produces a sinusoidal periodic embedding for a sequence of values in [-1, +1].</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.TimeSeriesSinusoidalPeriodicEmbedding.__init__","title":"<code>__init__(embedding_dim)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>embedding_dim</code> <code>int</code> <p>embedding size.</p> required"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.TimeSeriesSinusoidalPeriodicEmbedding.forward","title":"<code>forward(x)</code>","text":"<p><code>x</code> is expected to be [batch_size, seqlen, 1].</p>"},{"location":"API/models/buildings_bench-models/#zeroembedding","title":"ZeroEmbedding","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.ZeroEmbedding","title":"<code>buildings_bench.models.transformers.ZeroEmbedding</code>","text":"<p>               Bases: <code>Module</code></p> <p>Outputs zeros of the desired output dim.</p>"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.ZeroEmbedding.__init__","title":"<code>__init__(embedding_dim)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>embedding_dim</code> <code>int</code> <p>embedding size.</p> required"},{"location":"API/models/buildings_bench-models/#buildings_bench.models.transformers.ZeroEmbedding.forward","title":"<code>forward(x)</code>","text":"<p><code>x</code> is expected to be [batch_size, seqlen, 1].</p>"},{"location":"API/models/buildings_bench-models/#persistence-ensemble","title":"Persistence Ensemble","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.persistence.AveragePersistence","title":"<code>buildings_bench.models.persistence.AveragePersistence</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Predict each hour as the average over each previous day.</p>"},{"location":"API/models/buildings_bench-models/#previous-day-persistence","title":"Previous Day Persistence","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.persistence.CopyLastDayPersistence","title":"<code>buildings_bench.models.persistence.CopyLastDayPersistence</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Predict each hour as the same hour from the previous day.</p>"},{"location":"API/models/buildings_bench-models/#previous-week-persistence","title":"Previous Week Persistence","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.persistence.CopyLastWeekPersistence","title":"<code>buildings_bench.models.persistence.CopyLastWeekPersistence</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Predict each hour as the same hour from the previous week.</p>"},{"location":"API/models/buildings_bench-models/#linear-regression","title":"Linear Regression","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.linear_regression.LinearRegression","title":"<code>buildings_bench.models.linear_regression.LinearRegression</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Linear regression model that does direct forecasting.</p> <p>It has one weight W and one bias b. The output is computed as y = Wx + b, where W is a matrix of shape [pred_len, context_len].</p>"},{"location":"API/models/buildings_bench-models/#dlinear","title":"DLinear","text":""},{"location":"API/models/buildings_bench-models/#buildings_bench.models.dlinear_regression.DLinearRegression","title":"<code>buildings_bench.models.dlinear_regression.DLinearRegression</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Decomposition-Linear</p>"},{"location":"API/utilities/buildings_bench-evaluation/","title":"buildings_bench.evaluation","text":"<p>The <code>buildings_bench.evaluation</code> module contains the main functionality for evaluting a model on the benchmark tasks.</p> <p>The <code>buildings_bench.evaluation.managers.DatasetMetricsManager</code> class is the main entry point.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#simple-usage","title":"Simple usage","text":"<pre><code>from buildings_bench import BuildingTypes\nfrom buildings_bench.evaluation.managers import DatasetMetricsManager\n\n# By default, the DatasetMetricsManager keeps track of NRMSE, NMAE, and NMBE\nmetrics_manager = DatasetMetricsManager()\n\n# Iterate over the dataset using our building dataset generator\nfor building_name, building_dataset in buildings_datasets_generator:\n\n    # Register a new building with the manager\n    metrics_manager.add_building_to_dataset_if_missing(\n        dataset_name, building_name,\n    )\n\n    # Your model makes predictions\n    # ...\n\n    # Register the predictions with the manager\n    metrics_manager(\n        dataset_name,                 # the name of the dataset, e.g., electricity\n        building_name,                # the name of the building, e.g., MT_001\n        continuous_targets,           # the ground truth 24 hour targets\n        predictions,                  # the model's 24 hour predictions\n        BuildingTypes.RESIDENTIAL_INT,    # an int indicating the building type\n    )\n</code></pre>"},{"location":"API/utilities/buildings_bench-evaluation/#advanced-usage-with-scoring-rule","title":"Advanced usage (with scoring rule)","text":"<pre><code>from buildings_bench.evaluation.managers import DatasetMetricsManager\nfrom buildings_bench.evaluation import scoring_rule_factory\n\nmetrics_manager = DatasetMetricsManager(scoring_rule = scoring_rule_factory('crps'))\n\n# Iterate over the dataset\nfor building_name, building_dataset in buildings_datasets_generator:\n\n    # Register a new building with the manager\n    metrics_manager.add_building_to_dataset_if_missing(\n        dataset_name, building_name,\n    )\n\n    # Your model makes predictions\n    # ...\n\n    # Register the predictions with the manager\n    metrics_manager(\n        dataset_name,           # the name of the dataset, e.g., electricity\n        building_name,          # the name of the building, e.g., MT_001\n        continuous_targets,     # the ground truth 24 hour targets\n        predictions,            # the model's 24 hour predictions\n        building_types_mask,    # a boolean tensor indicating building type\n        y_categories=targets,   # for scoring rules, the ground truth (discrete categories if using tokenization)\n        y_distribution_params=distribution_params, # for scoring rules, the distribution parameters\n        centroids=centroids   # for scoring rules with categorical variables, the centroid values\n    )\n</code></pre>"},{"location":"API/utilities/buildings_bench-evaluation/#metrics_factory","title":"metrics_factory","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics_factory","title":"<code>buildings_bench.evaluation.metrics_factory(name, types=[MetricType.SCALAR])</code>","text":"<p>Create a metric from a name. By default, will return a scalar metric.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric.</p> required <code>types</code> <code>List[MetricTypes]</code> <p>The types of the metric.         </p> <code>[SCALAR]</code> <p>Returns:     metrics_list (List[Metric]): A list of metrics.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#scoring_rule_factory","title":"scoring_rule_factory","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.scoring_rule_factory","title":"<code>buildings_bench.evaluation.scoring_rule_factory(name)</code>","text":"<p>Create a scoring rule from a name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the scoring rule.</p> required <p>Returns:     sr (ScoringRule): A scoring rule.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#all_metrics_list","title":"all_metrics_list","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.all_metrics_list","title":"<code>buildings_bench.evaluation.all_metrics_list()</code>","text":"<p>Returns all registered metrics.</p> <p>Returns:</p> Name Type Description <code>metrics_list</code> <code>List[Metric]</code> <p>A list of metrics.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildingtypes","title":"BuildingTypes","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.BuildingTypes","title":"<code>buildings_bench.evaluation.managers.BuildingTypes</code>","text":"<p>Enum for supported types of buildings.</p> <p>Attributes:</p> Name Type Description <code>RESIDENTIAL</code> <code>str</code> <p>Residential building type.</p> <code>COMMERCIAL</code> <code>str</code> <p>Commercial building type.</p> <code>RESIDENTIAL_INT</code> <code>int</code> <p>Integer representation of residential building type (0).</p> <code>COMMERCIAL_INT</code> <code>int</code> <p>Integer representation of commercial building type (1).</p>"},{"location":"API/utilities/buildings_bench-evaluation/#datasetmetricsmanager","title":"DatasetMetricsManager","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.DatasetMetricsManager","title":"<code>buildings_bench.evaluation.managers.DatasetMetricsManager</code>","text":"<p>A class that manages a MetricsManager for each building in one or more benchmark datasets.  One DatasetMetricsManager can be used to keep track of all metrics when evaluating a model on all of the benchmark's datasets.</p> <p>This class wil create a Pandas Dataframe summary containing the metrics for each building.</p> <p>Default metrics are NRMSE (CVRMSE), NMAE, NMBE.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.DatasetMetricsManager.__call__","title":"<code>__call__(dataset_name, building_id, y_true, y_pred, building_types_mask=None, building_type=BuildingTypes.COMMERCIAL_INT, **kwargs)</code>","text":"<p>Compute metrics for a batch of predictions for a single building in a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset.</p> required <code>building_id</code> <code>str</code> <p>The unique building identifier.</p> required <code>y_true</code> <code>Tensor</code> <p>The true (unscaled) load values. (continuous) shape is [batch_size, pred_len, 1]</p> required <code>y_pred</code> <code>Tensor</code> <p>The predicted (unscaled) load values. (continuous) shape is [batch_size, pred_len, 1]</p> required <code>building_types_mask</code> <code>Tensor</code> <p>A boolean mask indicating the building type of each building. True (1) if commercial, False (0). Shape is [batch_size]. Default is None.</p> <code>None</code> <code>building_type</code> <code>int</code> <p>The building type of the batch. Can be provided  instead of building_types_mask if all buildings are of the same type.</p> <code>COMMERCIAL_INT</code> <p>Other Parameters:</p> Name Type Description <code>y_categories</code> <code>Tensor</code> <p>The true load values. (quantized)</p> <code>y_distribution_params</code> <code>Tensor</code> <p>logits, Gaussian params, etc.</p> <code>centroids</code> <code>Tensor</code> <p>The bin values for the quantized load.</p> <code>loss</code> <code>Tensor</code> <p>The loss for the batch.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.DatasetMetricsManager.__init__","title":"<code>__init__(metrics=default_metrics, scoring_rule=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>List[Metric]</code> <p>A list of metrics to compute for each building type.</p> <code>default_metrics</code> <code>scoring_rule</code> <code>ScoringRule</code> <p>A scoring rule to compute for each building type.</p> <code>None</code>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.DatasetMetricsManager.add_building_to_dataset_if_missing","title":"<code>add_building_to_dataset_if_missing(dataset_name, building_id)</code>","text":"<p>If the building does not exist, add a new MetricsManager for the building.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset.</p> required <code>building_id</code> <code>str</code> <p>The unique building identifier.</p> required"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.DatasetMetricsManager.get_building_from_dataset","title":"<code>get_building_from_dataset(dataset_name, building_id)</code>","text":"<p>If the dataset and building exist, return the MetricsManager for the building.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset.</p> required <code>building_id</code> <code>str</code> <p>The unique building identifier.</p> required <p>Returns:</p> Type Description <code>Optional[MetricsManager]</code> <p>A MetricsManager if the dataset and building exist, otherwise None.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.DatasetMetricsManager.summary","title":"<code>summary(dataset_name=None)</code>","text":"<p>Return a summary of the metrics for the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset to summarize. If None, summarize all datasets.</p> <code>None</code> <p>Returns:     A Pandas dataframe with the following columns:</p> <pre><code>    - dataset: The name of the dataset.\n    - building_id: The unique ID of the building.\n    - building_type: The type of the building.\n    - metric: The name of the metric.\n    - metric_type: The type of the metric. (scalar or hour_of_day)\n    - value: The value of the metric.\n</code></pre>"},{"location":"API/utilities/buildings_bench-evaluation/#metricsmanager","title":"MetricsManager","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.MetricsManager","title":"<code>buildings_bench.evaluation.managers.MetricsManager</code>","text":"<p>A class that keeps track of all metrics (and a scoring rule)for one or more buildings.</p> <p>Metrics are computed for each building type (residential and commercial).</p> <p>Example:</p> <pre><code>from buildings_bench.evaluation.managers import MetricsManager\nfrom buildings_bench.evaluation import metrics_factory\nfrom buildings_bench import BuildingTypes\nimport torch\n\n\nmetrics_manager = MetricsManager(metrics=metrics_factory('cvrmse'))\n\nmetrics_manager(\n    y_true=torch.FloatTensor([1, 2, 3]).view(1,3,1),\n    y_pred=torch.FloatTensor([1, 2, 3]).view(1,3,1),\n    building_type = BuildingTypes.RESIDENTIAL_INT\n)\n\nfor metric in metrics_manager.metrics[BuildingTypes.RESIDENTIAL]:\n    metric.mean()\n    print(metric.value) # prints tensor(0.)\n</code></pre>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.MetricsManager.__call__","title":"<code>__call__(y_true, y_pred, building_types_mask=None, building_type=BuildingTypes.COMMERCIAL_INT, **kwargs)</code>","text":"<p>Compute metrics for a batch of predictions.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>Tensor</code> <p>The true (unscaled) load values. (continuous) shape is [batch_size, pred_len, 1]</p> required <code>y_pred</code> <code>Tensor</code> <p>The predicted (unscaled) load values. (continuous) shape is [batch_size, pred_len, 1]</p> required <code>building_types_mask</code> <code>Tensor</code> <p>A boolean mask indicating the building type of each building. True (1) if commercial, False (0). Shape is [batch_size].</p> <code>None</code> <code>building_type</code> <code>int</code> <p>The building type of the batch. Can be provided  instead of building_types_mask if all buildings are of the same type.</p> <code>COMMERCIAL_INT</code> <p>Other Parameters:</p> Name Type Description <code>y_categories</code> <code>Tensor</code> <p>The true load values. (quantized)</p> <code>y_distribution_params</code> <code>Tensor</code> <p>logits, Gaussian params, etc.</p> <code>centroids</code> <code>Tensor</code> <p>The bin values for the quantized load.</p> <code>loss</code> <code>Tensor</code> <p>The loss for the batch.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.MetricsManager.__init__","title":"<code>__init__(metrics=None, scoring_rule=None)</code>","text":"<p>Initializes the MetricsManager.</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>List[Metric]</code> <p>A list of metrics to compute for each building type.</p> <code>None</code> <code>scoring_rule</code> <code>ScoringRule</code> <p>A scoring rule to compute for each building type.</p> <code>None</code>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.MetricsManager.get_ppl","title":"<code>get_ppl()</code>","text":"<p>Returns the perplexity of the accumulated loss.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.MetricsManager.reset","title":"<code>reset(loss=True)</code>","text":"<p>Reset the metrics.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.managers.MetricsManager.summary","title":"<code>summary(with_loss=False, with_ppl=False)</code>","text":"<p>Return a summary of the metrics for the dataset.</p> <p>A summary maps keys to objects of type Metric or ScoringRule.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#metrictype","title":"MetricType","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.MetricType","title":"<code>buildings_bench.evaluation.metrics.MetricType</code>","text":"<p>Enum class for metric types.</p> <p>Attributes:</p> Name Type Description <code>SCALAR</code> <code>str</code> <p>A scalar metric.</p> <code>HOUR_OF_DAY</code> <code>str</code> <p>A metric that is calculated for each hour of the day.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildingsbenchmetric","title":"BuildingsBenchMetric","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.BuildingsBenchMetric","title":"<code>buildings_bench.evaluation.metrics.BuildingsBenchMetric</code>","text":"<p>An abstract class for all metrics.</p> <p>The basic idea is to acculumate the errors etc. in a list and then calculate the mean of the errors etc. at the end of the evaluation.</p> <p>Calling the metric will add the error to the list of errors. Calling <code>.mean()</code> will calculate the mean of the errors, populating the <code>.value</code> attribute.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the metric.</p> <code>type</code> <code>MetricType</code> <p>The type of the metric.</p> <code>value</code> <code>float</code> <p>The value of the metric.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#metric","title":"Metric","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.Metric","title":"<code>buildings_bench.evaluation.metrics.Metric</code>","text":"<p>               Bases: <code>BuildingsBenchMetric</code></p> <p>A class that represents an error metric.  </p> <p>Example:</p> <pre><code>rmse = Metric('rmse', MetricType.SCALAR, squared_error, sqrt=True)\nmae = Metric('mae', MetricType.SCALAR, absolute_error)\nnmae = Metric('nmae', MetricType.SCALAR, absolute_error, normalize=True)\ncvrmse = Metric('cvrmse', MetricType.SCALAR, squared_error, normalize=True, sqrt=True)\nnmbe = Metric('nmbe', MetricType.SCALAR, bias_error, normalize=True)\n</code></pre>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.Metric.__call__","title":"<code>__call__(y_true, y_pred)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>Tensor</code> <p>shape [batch_size, pred_len]</p> required <code>y_pred</code> <code>Tensor</code> <p>shape [batch_size, pred_len]</p> required"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.Metric.__init__","title":"<code>__init__(name, type, function, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the metric.</p> required <code>type</code> <code>MetricType</code> <p>The type of the metric.</p> required <code>function</code> <code>Callable</code> <p>A function that takes two tensors and returns a tensor.</p> required <p>Other Parameters:</p> Name Type Description <code>normalize</code> <code>bool</code> <p>Whether to normalize the error.</p> <code>sqrt</code> <code>bool</code> <p>Whether to take the square root of the error.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.Metric.mean","title":"<code>mean()</code>","text":"<p>Calculate the mean of the error metric.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.Metric.reset","title":"<code>reset()</code>","text":"<p>Reset the metric.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#absolute_error","title":"absolute_error","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.absolute_error","title":"<code>buildings_bench.evaluation.metrics.absolute_error(y_true, y_pred)</code>","text":"<p>A PyTorch method that calculates the absolute error (AE) metric.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>Tensor</code> <p>[batch, pred_len]</p> required <code>y_pred</code> <code>Tensor</code> <p>[batch, pred_len]</p> required <p>Returns:</p> Name Type Description <code>error</code> <code>Tensor</code> <p>[batch, pred_len]</p>"},{"location":"API/utilities/buildings_bench-evaluation/#squared_error","title":"squared_error","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.squared_error","title":"<code>buildings_bench.evaluation.metrics.squared_error(y_true, y_pred)</code>","text":"<p>A PyTorch method that calculates the squared error (SE) metric.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>Tensor</code> <p>[batch, pred_len]</p> required <code>y_pred</code> <code>Tensor</code> <p>[batch, pred_len]</p> required <p>Returns:</p> Name Type Description <code>error</code> <code>Tensor</code> <p>[batch, pred_len]</p>"},{"location":"API/utilities/buildings_bench-evaluation/#bias_error","title":"bias_error","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.metrics.bias_error","title":"<code>buildings_bench.evaluation.metrics.bias_error(y_true, y_pred)</code>","text":"<p>A PyTorch method that calculates the bias error (BE) metric.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>Tensor</code> <p>[batch, pred_len]</p> required <code>y_pred</code> <code>Tensor</code> <p>[batch, pred_len]</p> required <p>Returns:</p> Name Type Description <code>error</code> <code>Tensor</code> <p>[batch, pred_len]</p>"},{"location":"API/utilities/buildings_bench-evaluation/#scoringrule","title":"ScoringRule","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.scoring_rules.ScoringRule","title":"<code>buildings_bench.evaluation.scoring_rules.ScoringRule</code>","text":"<p>               Bases: <code>BuildingsBenchMetric</code></p> <p>An abstract class for all scoring rules.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#rankedprobabilityscore","title":"RankedProbabilityScore","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.scoring_rules.RankedProbabilityScore","title":"<code>buildings_bench.evaluation.scoring_rules.RankedProbabilityScore</code>","text":"<p>               Bases: <code>ScoringRule</code></p> <p>A class that calculates the ranked probability score (RPS) metric for categorical distributions.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.scoring_rules.RankedProbabilityScore.rps","title":"<code>rps(y_true, y_pred_logits, centroids)</code>","text":"<p>A PyTorch method that calculates the ranked probability score metric    for categorical distributions.</p> <p>Since the bin values are centroids of clusters along the real line,    we have to compute the width of the bins by summing the distance to    the left and right centroids of the bin (divided by 2), except for    the first and last bins, where we only need to sum the distance to    the right centroid of the first bin and the left centroid of the    last bin, respectively.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>Tensor</code> <p>of shape [batch_size, seq_len, 1] categorical labels</p> required <code>y_pred_logits</code> <code>Tensor</code> <p>of shape [batch_size, seq_len, vocab_size] logits</p> required <code>centroids</code> <code>Tensor</code> <p>of shape [vocab_size]</p> required"},{"location":"API/utilities/buildings_bench-evaluation/#continuousrankedprobabilityscore","title":"ContinuousRankedProbabilityScore","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.scoring_rules.ContinuousRankedProbabilityScore","title":"<code>buildings_bench.evaluation.scoring_rules.ContinuousRankedProbabilityScore</code>","text":"<p>               Bases: <code>ScoringRule</code></p> <p>A class that calculates the Gaussian continuous ranked probability score (CRPS) metric.</p>"},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.scoring_rules.ContinuousRankedProbabilityScore.crps","title":"<code>crps(true_continuous, y_pred_distribution_params)</code>","text":"<p>Computes the Gaussian CRPS.</p> <p>Parameters:</p> Name Type Description Default <code>true_continuous</code> <code>Tensor</code> <p>of shape [batch_size, seq_len, 1]</p> required <code>y_pred_distribution_params</code> <code>Tensor</code> <p>of shape [batch_size, seq_len, 2]</p> required"},{"location":"API/utilities/buildings_bench-evaluation/#aggregate","title":"aggregate","text":""},{"location":"API/utilities/buildings_bench-evaluation/#buildings_bench.evaluation.aggregate.return_aggregate_median","title":"<code>buildings_bench.evaluation.aggregate.return_aggregate_median(model_list, results_dir, experiment='zero_shot', metrics=['cvrmse'], exclude_simulated=True, only_simulated=False, oov_list=[], reps=50000)</code>","text":"<p>Compute the aggregate median for a list of models and metrics over all buildings. Also returns the stratified 95% boostrap CIs for the aggregate median.</p> <p>Parameters:</p> Name Type Description Default <code>model_list</code> <code>list</code> <p>List of models to compute aggregate median for.</p> required <code>results_dir</code> <code>str</code> <p>Path to directory containing results.</p> required <code>experiment</code> <code>str</code> <p>Experiment type. Defaults to 'zero_shot'. Options: 'zero_shot', 'transfer_learning'.</p> <code>'zero_shot'</code> <code>metrics</code> <code>list</code> <p>List of metrics to compute aggregate median for. Defaults to ['cvrmse'].</p> <code>['cvrmse']</code> <code>exclude_simulated</code> <code>bool</code> <p>Whether to exclude simulated data. Defaults to True.</p> <code>True</code> <code>only_simulated</code> <code>bool</code> <p>Whether to only include simulated data. Defaults to False.</p> <code>False</code> <code>oov_list</code> <code>list</code> <p>List of OOV buildings to exclude. Defaults to [].</p> <code>[]</code> <code>reps</code> <code>int</code> <p>Number of bootstrap replicates to use. Defaults to 50000.</p> <code>50000</code> <p>Returns:</p> Name Type Description <code>result_dict</code> <code>Dict</code> <p>Dictionary containing aggregate median and CIs for each metric and building type.</p>"},{"location":"API/utilities/buildings_bench-tokenizer/","title":"buildings_bench.tokenizer","text":""},{"location":"API/utilities/buildings_bench-tokenizer/#tokenizer-quick-start","title":"Tokenizer Quick Start","text":""},{"location":"API/utilities/buildings_bench-tokenizer/#instantiate-a-loadquantizer","title":"Instantiate a LoadQuantizer","text":"<pre><code>from buildings_bench.tokenizer import LoadQuantizer\n\ntransform_path =  Path(os.environ.get('BUILDINGS_BENCH')) / 'metadata' / 'transforms'\n\nload_transform = LoadQuantizer(\n    with_merge=True,  # Default vocabulary has merged KMeans centroids\n    num_centroids=2274, # Default vocabulary has 2,274 tokens\n    device='cuda:0' if 'cuda' in args.device else 'cpu')\n\n# Load the saved faiss KMeans state from disk\nload_transform.load(transform_path)\n</code></pre>"},{"location":"API/utilities/buildings_bench-tokenizer/#quantize-a-load-time-series","title":"Quantize a load time series","text":"<pre><code>batch['load'] = load_transform.transform(batch['load'])\n</code></pre>"},{"location":"API/utilities/buildings_bench-tokenizer/#dequantize-transformer-predictions","title":"Dequantize transformer predictions","text":"<pre><code># predictions are a Tensor of shape [batch_size, pred_len, 1] of quantized values\n# distribution_params is a Tensor of shape [batch_size, pred_len, num_centroids] of logits\npredictions, distribution_params = model.predict(batch)\n\n# Dequantize the predictions\npredictions = load_transform.undo_transform(predictions)\n</code></pre>"},{"location":"API/utilities/buildings_bench-tokenizer/#extract-the-categorical-distribution","title":"Extract the categorical distribution","text":"<pre><code># First, apply softmax to the logits to normalize them into a categorical distribution\ndistribution_params = torch.softmax(distribution_params, dim=-1)\n\n# The merged centroid values are the load values corresponding\n# to each token. Note that the merged centroids are already sorted\n# in increasing order.\n\n# if using merge...\nload_values = load_transform.merged_centroids\n# else, load_values = load_transform.kmeans.centroids.squeeze()\n# Now, distribution_params[i] is the probability \n# assigned to load_values[i].\n</code></pre>"},{"location":"API/utilities/buildings_bench-tokenizer/#loadquantizer","title":"LoadQuantizer","text":""},{"location":"API/utilities/buildings_bench-tokenizer/#buildings_bench.tokenizer.LoadQuantizer","title":"<code>buildings_bench.tokenizer.LoadQuantizer</code>","text":"<p>Quantize load timeseries with KMeans. Merge centroids that are within a threshold.</p>"},{"location":"API/utilities/buildings_bench-tokenizer/#buildings_bench.tokenizer.LoadQuantizer.__init__","title":"<code>__init__(seed=1, num_centroids=2274, with_merge=False, merge_threshold=0.01, device='cpu')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>random seed. Default: 1.</p> <code>1</code> <code>num_centroids</code> <code>int</code> <p>number of centroids: Default: 2274.</p> <code>2274</code> <code>with_merge</code> <code>bool</code> <p>whether to merge centroids that are within a threshold: Default: False.</p> <code>False</code> <code>merge_threshold</code> <code>float</code> <p>threshold for merging centroids. Default: 0.01 (kWh).</p> <code>0.01</code> <code>device</code> <code>str</code> <p>cpu or cuda. Default: cpu.</p> <code>'cpu'</code>"},{"location":"API/utilities/buildings_bench-tokenizer/#buildings_bench.tokenizer.LoadQuantizer.train","title":"<code>train(sample)</code>","text":"<p>Fit KMeans to a subset of the data. </p> <p>Optionally, merge centroids that are within a threshold.</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>ndarray</code> <p>shape [num_samples, 1]</p> required"},{"location":"API/utilities/buildings_bench-tokenizer/#buildings_bench.tokenizer.LoadQuantizer.transform","title":"<code>transform(sample)</code>","text":"<p>Quantize a sample of load values into a sequence of indices.</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>Union[ndarray, Tensor]</code> <p>of shape (n, 1) or (b,n,1).  type is numpy if device is cpu or torch Tensor if device is cuda.</p> required <p>Returns:</p> Name Type Description <code>sample</code> <code>Union[ndarray, Tensor]</code> <p>of shape (n, 1) or (b,n,1).</p>"},{"location":"API/utilities/buildings_bench-tokenizer/#buildings_bench.tokenizer.LoadQuantizer.undo_transform","title":"<code>undo_transform(sample)</code>","text":"<p>Dequantize a sample of integer indices into a sequence of load values.</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>Union[ndarray, Tensor]</code> <p>of shape (n, 1) or (b,n,1).  type is numpy if device is cpu or torch Tensor if device is cuda.</p> required <p>Returns:</p> Name Type Description <code>sample</code> <code>Union[ndarray, Tensor]</code> <p>of shape (n, 1) or (b,n,1).</p>"},{"location":"API/utilities/buildings_bench-transforms/","title":"buildings_bench.transforms","text":""},{"location":"API/utilities/buildings_bench-transforms/#boxcoxtransform","title":"BoxCoxTransform","text":""},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.BoxCoxTransform","title":"<code>buildings_bench.transforms.BoxCoxTransform</code>","text":"<p>A class that computes and applies the Box-Cox transform to data.</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.BoxCoxTransform.__init__","title":"<code>__init__(max_datapoints=1000000)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>max_datapoints</code> <code>int</code> <p>If the number of datapoints is greater than this, subsample.</p> <code>1000000</code>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.BoxCoxTransform.load","title":"<code>load(saved_path)</code>","text":"<p>Load the Box-Cox transform</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.BoxCoxTransform.save","title":"<code>save(output_path)</code>","text":"<p>Save the Box-Cox transform</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.BoxCoxTransform.train","title":"<code>train(data)</code>","text":"<p>Train the Box-Cox transform on the data with sklearn.preprocessing.PowerTransformer.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array</code> <p>of shape (n, 1) or (b,n,1)</p> required"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.BoxCoxTransform.transform","title":"<code>transform(sample)</code>","text":"<p>Transform a sample via Box-Cox. Not ran on the GPU, so input/output are numpy arrays.</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>ndarray</code> <p>of shape (n, 1) or (b,n,1) </p> required <p>Returns:</p> Name Type Description <code>transformed_sample</code> <code>ndarray</code> <p>of shape (n, 1) or (b,n,1)</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.BoxCoxTransform.undo_transform","title":"<code>undo_transform(sample)</code>","text":"<p>Undo the transformation of a sample via Box-Cox</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>Union[ndarray, LongTensor]</code> <p>of shape (n, 1) or (b,n,1).  numpy if device is cpu or torch Tensor if device is cuda.</p> required <p>Returns:</p> Name Type Description <code>unscaled_sample</code> <code>Union[ndarray, LongTensor]</code> <p>of shape (n, 1) or (b,n,1).</p>"},{"location":"API/utilities/buildings_bench-transforms/#standardscalertransform","title":"StandardScalerTransform","text":""},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.StandardScalerTransform","title":"<code>buildings_bench.transforms.StandardScalerTransform</code>","text":"<p>A class that standardizes data by removing the mean and scaling to unit variance.</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.StandardScalerTransform.__init__","title":"<code>__init__(max_datapoints=1000000, device='cpu')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>max_datapoints</code> <code>int</code> <p>If the number of datapoints is greater than this, subsample.</p> <code>1000000</code> <code>device</code> <code>str</code> <p>'cpu' or 'cuda'</p> <code>'cpu'</code>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.StandardScalerTransform.load","title":"<code>load(saved_path)</code>","text":"<p>Load the StandardScaler transform</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.StandardScalerTransform.save","title":"<code>save(output_path)</code>","text":"<p>Save the StandardScaler transform</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.StandardScalerTransform.train","title":"<code>train(data)</code>","text":"<p>Train the StandardScaler transform on the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array</code> <p>of shape (n, 1) or (b,n,1)</p> required"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.StandardScalerTransform.transform","title":"<code>transform(sample)</code>","text":"<p>Transform a sample via StandardScaler</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>Union[ndarray, LongTensor]</code> <p>shape (n, 1) or (b,n,1) </p> required <p>Returns:     transformed_samples (torch.Tensor): shape (n, 1) or (b,n,1)</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.StandardScalerTransform.undo_transform","title":"<code>undo_transform(sample)</code>","text":"<p>Undo the transformation of a sample via StandardScaler</p> <p>Parameters:</p> Name Type Description Default <code>sample</code> <code>ndarray</code> <p>of shape (n, 1) or (b,n,1) or torch.Tensor of shape (n, 1) or (b,n,1)</p> required <p>Returns:</p> Name Type Description <code>unscaled_sample</code> <code>Tensor</code> <p>of shape (n, 1) or (b,n,1)</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.StandardScalerTransform.undo_transform_std","title":"<code>undo_transform_std(scaled_std)</code>","text":"<p>Undo transform for standard deviation.</p> <p>Parameters:</p> Name Type Description Default <code>scaled_std</code> <code>Tensor</code> <p>of shape (n, 1) or (b,n,1)</p> required <p>Returns:</p> Name Type Description <code>unscaled_std</code> <code>Tensor</code> <p>of shape (n, 1) or (b,n,1)</p>"},{"location":"API/utilities/buildings_bench-transforms/#latlontransform","title":"LatLonTransform","text":""},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.LatLonTransform","title":"<code>buildings_bench.transforms.LatLonTransform</code>","text":"<p>Pre-processing lat,lon data with standard normalization by Buildings-900K training set.</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.LatLonTransform.transform","title":"<code>transform(puma_id)</code>","text":"<p>Look up a PUMA ID's normalized Lat/Lon centroid.</p> <p>This is used in the Buildings-900K Dataset to look up a lat/lon for each building's PUMA.</p> <p>Parameters:</p> Name Type Description Default <code>puma_id</code> <code>str</code> <p>PUMA ID</p> required <p>Returns:</p> Name Type Description <code>centroid</code> <code>ndarray</code> <p>of shape (1,2)</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.LatLonTransform.transform_latlon","title":"<code>transform_latlon(latlon)</code>","text":"<p>Transform a raw Lat/Lon sample into a normalized Lat/Lon sample</p> <p>Parameters:</p> Name Type Description Default <code>latlon</code> <code>ndarray</code> <p>of shape (2,).</p> required <p>Returns:</p> Name Type Description <code>transformed_latlon</code> <code>ndarray</code> <p>of shape (2,).</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.LatLonTransform.undo_transform","title":"<code>undo_transform(normalized_latlon)</code>","text":"<p>Undo the transformation of a sample</p> <p>Parameters:</p> Name Type Description Default <code>normalized_latlon</code> <code>ndarray</code> <p>of shape (n, 2) or (b,n,2).</p> required <p>Returns:</p> Name Type Description <code>unnormalized_latlon</code> <code>ndarray</code> <p>of shape (n, 2) or (b,n,2).</p>"},{"location":"API/utilities/buildings_bench-transforms/#timestamptransform","title":"TimestampTransform","text":""},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.TimestampTransform","title":"<code>buildings_bench.transforms.TimestampTransform</code>","text":"<p>Extract timestamp features from a Pandas timestamp Series.</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.TimestampTransform.__init__","title":"<code>__init__(is_leap_year=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>is_leap_year</code> <code>bool</code> <p>Whether the year of the building data is a leap year or not.</p> <code>False</code>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.TimestampTransform.transform","title":"<code>transform(timestamp_series)</code>","text":"<p>Extract timestamp features from a Pandas timestamp Series.</p> <ul> <li>Day of week (0-6)</li> <li>Day of year (0-364)</li> <li>Hour of day (0-23)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>timestamp_series</code> <code>DataFrame</code> <p>of shape (n,) or (b,n)</p> required <p>Returns:</p> Name Type Description <code>time_features</code> <code>ndarray</code> <p>of shape (n,3) or (b,n,3)</p>"},{"location":"API/utilities/buildings_bench-transforms/#buildings_bench.transforms.TimestampTransform.undo_transform","title":"<code>undo_transform(time_features)</code>","text":"<p>Convert normalized time features back to original time features</p> <p>Parameters:</p> Name Type Description Default <code>time_features</code> <code>ndarray</code> <p>of shape (n, 3) or (b,n,3)</p> required <p>Returns:</p> Name Type Description <code>unnormalized_time_features</code> <code>ndarray</code> <p>of shape (n, 3) or (b,n,3)</p>"},{"location":"API/utilities/buildings_bench-utils/","title":"buildings_bench.utils","text":""},{"location":"API/utilities/buildings_bench-utils/#common-utilities","title":"Common Utilities","text":""},{"location":"API/utilities/buildings_bench-utils/#buildings_bench.utils","title":"<code>buildings_bench.utils</code>","text":""},{"location":"API/utilities/buildings_bench-utils/#buildings_bench.utils.get_puma_county_lookup_table","title":"<code>get_puma_county_lookup_table(metadata_dir)</code>","text":"<p>Build a puma-county lookup table.</p> <p>The weather files are organized by U.S. county. We need to map counties to PUMAs and ensure we drop counties without weather data  (only done when using weather).</p> <p>Parameters:</p> Name Type Description Default <code>metadata_dir</code> <code>Path</code> <p>Path to the metadata folder of BuildingsBench</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: the puma-county lookup table</p>"},{"location":"API/utilities/buildings_bench-utils/#buildings_bench.utils.load_model_checkpoint","title":"<code>load_model_checkpoint(path, model, optimizer, scheduler, local_rank)</code>","text":"<p>Load model checkpoint.</p>"},{"location":"API/utilities/buildings_bench-utils/#buildings_bench.utils.save_model_checkpoint","title":"<code>save_model_checkpoint(model, optimizer, scheduler, step, path)</code>","text":"<p>Save model checkpoint.</p>"},{"location":"API/utilities/buildings_bench-utils/#buildings_bench.utils.set_seed","title":"<code>set_seed(seed=42)</code>","text":"<p>Set random seed for reproducibility.</p>"},{"location":"API/utilities/buildings_bench-utils/#buildings_bench.utils.time_features_to_datetime","title":"<code>time_features_to_datetime(time_features, year)</code>","text":"<p>Convert time features to datetime objects.</p> <p>Parameters:</p> Name Type Description Default <code>time_features</code> <code>ndarray</code> <p>Array of time features. [:,0] is day of year, [:,1] is day of week, [:,2] is hour of day.</p> required <code>year</code> <code>int</code> <p>Year to use for datetime objects.</p> required <p>Returns:</p> Type Description <code>array</code> <p>np.array: Array of datetime objects.</p>"},{"location":"API/utilities/buildings_bench-utils/#buildings_bench.utils.worker_init_fn_eulp","title":"<code>worker_init_fn_eulp(worker_id)</code>","text":"<p>Set random seed for each worker and init file pointer for Buildings-900K dataset workers.</p> <p>Parameters:</p> Name Type Description Default <code>worker_id</code> <code>int</code> <p>worker id</p> required"}]}